[pytest]
# Test discovery
python_files = test_*.py
python_functions = test_*
python_classes = Test*
testpaths = tests

# Async support
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Parallel execution configuration
# Automatically uses optimal parallel execution when running 'uv run pytest'
addopts = -n 4 --dist=worksteal

# Test markers for grouping and filtering
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    http_mocking: marks tests that use HTTP mocking
    scrapy: marks tests that use Scrapy backend
    real_world: marks tests that use real websites
    performance: marks tests as performance benchmarks
    e2e: marks tests as end-to-end tests
    network: marks tests that require network access
    filesystem: marks tests that access filesystem
    gui: marks tests for GUI components
    backend: marks tests for backend components
    crawler: marks tests for crawler functionality
    processor: marks tests for content processing
    organizer: marks tests for document organization
    quality: marks tests for quality checking
    config: marks tests for configuration
    utils: marks tests for utility functions
    models: marks tests for data models
    storage: marks tests for storage functionality
    url: marks tests for URL handling
    versioning: marks tests for version management

# Coverage configuration (if using pytest-cov)
# --cov=src --cov-report=html --cov-report=term-missing --cov-fail-under=20

# Warnings configuration
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:scrapy.*
    ignore::UserWarning:playwright.*
    ignore::UserWarning:aiohttp.*