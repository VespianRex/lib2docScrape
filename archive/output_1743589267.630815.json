{"content": {"suites": {"0": {"status": {"total_pass": 6, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_backend_selector_advanced_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_mock_crawler_backend_edge_cases", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_content_processor.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 'This is a paragraph.' in ''\n", "test_name": "test_extract_text_basic", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'Article Title' in ''\n", "test_name": "test_extract_text_with_complex_content", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'Main Title' in ''\n", "test_name": "test_extract_text_with_mixed_content_types", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'Deeply nested paragraph.' in ''\n", "test_name": "test_extract_text_with_nested_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 'Special characters: &, <, >, \", \\'' in ''\n", "test_name": "test_extract_text_with_special_characters", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert '' == '# Title\\n\\nParagraph.'\n     \n     - # Title\n     - \n     - Paragraph.\n", "test_name": "test_format_as_markdown", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 'Content here.' in ''\n", "test_name": "test_process_basic", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert 'Visible text.' in ''\n", "test_name": "test_extract_text_with_scripts", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Content here.' in ''\n", "test_name": "test_script_tags_non_json_ld", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AssertionError: assert 'Content here.' in ''\n", "test_name": "test_script_tags_with_invalid_json", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AssertionError: assert 'Content here.' in ''\n", "test_name": "test_script_tags_with_different_types", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_scripts_with_data_attributes", "rerun": "0"}, "12": {"status": "FAIL", "message": "   assert '```javascript\\nconsole.log(\"Hello, World!\");\\n```' in ''\n", "test_name": "test_extract_code_blocks[javascript-console.log(\"Hello, World!\");-```javascript\\nconsole.log(\"Hello, World!\");\\n```]", "rerun": "0"}, "13": {"status": "FAIL", "message": "   assert '```python\\nprint(\"Hello, World!\")\\n```' in ''\n", "test_name": "test_extract_code_blocks[python-print(\"Hello, World!\")-```python\\nprint(\"Hello, World!\")\\n```]", "rerun": "0"}, "14": {"status": "FAIL", "message": "   assert '```ruby\\nputs \"Hello, Ruby!\"\\n```' in ''\n", "test_name": "test_extract_code_blocks[ruby-puts \"Hello, Ruby!\"-```ruby\\nputs \"Hello, Ruby!\"\\n```]", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AssertionError: assert '`Inline code`' in ''\n", "test_name": "test_extract_code_blocks[None-Inline code-`Inline code`]", "rerun": "0"}, "16": {"status": "FAIL", "message": "   assert '```python\\nprint(\"Hello, World!\")\\n```' in ''\n", "test_name": "test_extract_code_blocks_with_attributes", "rerun": "0"}, "17": {"status": "FAIL", "message": "   assert '```python\\ndef foo():\\n    return \"<div>HTML Content</div>\"\\n```' in ''\n", "test_name": "test_extract_code_blocks_with_nested_content", "rerun": "0"}, "18": {"status": "FAIL", "message": "   assert '```python\\nprint(\"Hello, Python!\")\\n```' in ''\n", "test_name": "test_code_blocks_with_disallowed_languages", "rerun": "0"}, "19": {"status": "FAIL", "message": "   assert 0 == 3\n    +  where 0 = len([])\n", "test_name": "test_extract_content_structure", "rerun": "0"}, "20": {"status": "FAIL", "message": "   assert 0 == 3\n    +  where 0 = len([])\n", "test_name": "test_extract_headings_hierarchy", "rerun": "0"}, "21": {"status": "PASS", "message": "", "test_name": "test_extract_metadata", "rerun": "0"}, "22": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_complex_metadata", "rerun": "0"}, "23": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_duplicates", "rerun": "0"}, "24": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_invalid_html", "rerun": "0"}, "25": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_missing_values", "rerun": "0"}, "26": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_schema_org_json_ld", "rerun": "0"}, "27": {"status": "PASS", "message": "", "test_name": "test_extract_metadata_with_all_types", "rerun": "0"}, "28": {"status": "PASS", "message": "", "test_name": "test_collect_assets", "rerun": "0"}, "29": {"status": "PASS", "message": "", "test_name": "test_images_with_data_urls", "rerun": "0"}, "30": {"status": "PASS", "message": "", "test_name": "test_extract_assets_with_invalid_urls", "rerun": "0"}, "31": {"status": "FAIL", "message": "   AssertionError: assert '[Good Link](https://valid.com)' in ''\n", "test_name": "test_extract_links_with_invalid_urls", "rerun": "0"}, "32": {"status": "FAIL", "message": "   AssertionError: assert '[Relative Link](https://example.com/subdir/page.html)' in ''\n", "test_name": "test_extract_links_with_relative_paths", "rerun": "0"}, "33": {"status": "FAIL", "message": "   assert \"[John's Page](https://example.com/page?name=John Doe&age=30)\" in ''\n", "test_name": "test_links_with_query_parameters", "rerun": "0"}, "34": {"status": "FAIL", "message": "   AssertionError: assert '[Section 1](https://example.com/page#section1)' in ''\n", "test_name": "test_links_with_anchors", "rerun": "0"}, "35": {"status": "FAIL", "message": "   AssertionError: assert '[Link without href](#)' in ''\n", "test_name": "test_anchor_tags_without_href", "rerun": "0"}, "36": {"status": "FAIL", "message": "   AssertionError: assert '[HTTPS Link](https://example.com)' in ''\n", "test_name": "test_links_with_various_protocols", "rerun": "0"}, "37": {"status": "FAIL", "message": "   AssertionError: assert '[Page 1](https://example.com/page1)' in ''\n", "test_name": "test_multiple_links_in_paragraph", "rerun": "0"}, "38": {"status": "FAIL", "message": "   AssertionError: assert '[](https://example.com)' in ''\n", "test_name": "test_links_with_no_text", "rerun": "0"}}, "status": {"total_pass": 11, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 28, "total_error": 0}}, "2": {"suite_name": "tests/test_content_processor_advanced.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_url_processor_port_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 0}}, "3": {"suite_name": "tests/test_content_processor_edge.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_empty_content", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'Test content' in ''\n", "test_name": "test_malformed_html", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert '\u4f60\u597d' in ''\n", "test_name": "test_special_characters", "rerun": "0"}, "3": {"status": "FAIL", "message": "       AssertionError: assert 0 > 1000\n        +  where 0 = len('')\n", "test_name": "test_large_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 'Test content' in ''\n", "test_name": "test_nested_structures", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'Valid content' in ''\n", "test_name": "test_javascript_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 'Valid content' in ''\n", "test_name": "test_style_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert 'Main content' in ''\n", "test_name": "test_iframe_handling", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Main content' in ''\n", "test_name": "test_form_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "4": {"suite_name": "tests/test_crawl4ai.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_basic", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawl_with_rate_limit", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_validate_content", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('content' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. Y...in in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'} or 'error' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. Y...in in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'})\n", "test_name": "test_process_content", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_backend_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metrics", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 == 500\n    +  where 0 = CrawlResult(url='https://invalid-url-that-does-not-exist.com', content={}, metadata={}, status=0, error='Failed after ...-does-not-exist.com:443 ssl:default [getaddrinfo failed]', timestamp=datetime.datetime(2025, 4, 2, 10, 14, 10, 997362)).status\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_concurrent_requests", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_crawl4ai_config_validation", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_ssl_context_configuration", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_custom_headers_handling", "rerun": "0"}, "12": {"status": "FAIL", "message": "   assert 200 == 403\n    +  where 200 = CrawlResult(url='https://other-domain.com/page', content={'html': '\\ufeff<!DOCTYPE html>\\n<html lang=\"ja\">\\n<head>\\n\\t...pe': 'text/html; charset=UTF-8'}}, status=200, error=None, timestamp=datetime.datetime(2025, 4, 2, 10, 14, 18, 288099)).status\n", "test_name": "test_domain_filtering", "rerun": "0"}, "13": {"status": "FAIL", "message": "   AssertionError: assert 5 == 3\n    +  where 5 = len([CrawlResult(url='https://example.com/page0', content={'html': '<!doctype html>\\n<html>\\n<head>\\n    <title>Example Do...T', 'Connection': 'keep-alive'}}, status=404, error=None, timestamp=datetime.datetime(2025, 4, 2, 10, 14, 23, 665350))])\n", "test_name": "test_url_queue_management", "rerun": "0"}}, "status": {"total_pass": 9, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "5": {"suite_name": "tests/test_crawl4ai_extended.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_crawl_with_urlinfo", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_crawl_depth_first", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_rate_limiting_precision", "rerun": "0"}, "3": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_concurrent_request_limit", "rerun": "0"}, "4": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_error_propagation", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'coroutine' object has no attribute '_session'\n", "test_name": "test_retry_behavior", "rerun": "0"}, "7": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_metrics_accuracy", "rerun": "0"}, "8": {"status": "FAIL", "message": "   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n", "test_name": "test_resource_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AttributeError: 'URLInfo' object has no attribute 'original_url'\n", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AttributeError: 'URLInfo' object has no attribute 'original_url'\n", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'URLInfo' object has no attribute 'original_url'\n", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}, "12": {"status": "FAIL", "message": "   assert 3 == 2\n    +  where 3 = len({<src.utils.url_info.URLInfo object at 0x000001BE15AC7C80>, <src.utils.url_info.URLInfo object at 0x000001BE15AC6CC0>, <src.utils.url_info.URLInfo object at 0x000001BE15AC7EC0>})\n", "test_name": "test_url_info_hashable", "rerun": "0"}, "13": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'Exception'>\n", "test_name": "test_url_info_immutable", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 14, "total_error": 0}}, "6": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_statistics_tracking", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_project_type_enum", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_project_identity", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_project_identifier", "rerun": "0"}, "14": {"status": "FAIL", "message": "           aiohttp.client_exceptions.ContentTypeError: 200, message='Attempt to decode JSON with unexpected mimetype: application/x-javascript', url='https://links.duckduckgo.com/506-01.js?q=python%2Bdocumentation'\n       src.utils.search.SearchError: Search error: 200, message='Attempt to decode JSON with unexpected mimetype: application/x-javascript', url='https://links.duckduckgo.com/506-01.js?q=python%2Bdocumentation'\n", "test_name": "test_duckduckgo_search", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute '_discover_urls'\n", "test_name": "test_url_discovery", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'ProjectIdentifier' object has no attribute '_identify_project_type'\n", "test_name": "test_project_type_detection", "rerun": "0"}}, "status": {"total_pass": 5, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 12, "total_error": 0}}, "7": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "FAIL", "message": "           AttributeError: type object 'IssueType' has no attribute 'PROCESSING'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n       AttributeError: type object 'IssueLevel' has no attribute 'CRITICAL'\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 10, "total_error": 0}}, "8": {"suite_name": "tests/test_gui.py", "tests": {"0": {"status": "FAIL", "message": "       jinja2.exceptions.TemplateNotFound: 'index.html' not found in search path: 'src/gui/templates'\n", "test_name": "test_home_page", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'error' == 'success'\n     \n     - success\n     + error\n", "test_name": "test_crawl_request", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_connection_manager", "rerun": "0"}, "3": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_crawler_thread", "rerun": "0"}, "4": {"status": "FAIL", "message": "   NameError: name 'ResultsViewer' is not defined\n", "test_name": "test_results_viewer", "rerun": "0"}, "5": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_save_results", "rerun": "0"}, "6": {"status": "FAIL", "message": "E   ModuleNotFoundError: No module named 'PyQt6'\n", "test_name": "test_error_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "9": {"suite_name": "tests/test_helpers.py", "tests": {"0": {"status": "FAIL", "message": "   assert (1743588926.497343 - 1743588925.9970465) >= 1.0\n", "test_name": "test_rate_limiter", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert ValueError('Attempt 1 failed') is None\n", "test_name": "test_retry_strategy", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'Timer' object has no attribute 'end_time'\n", "test_name": "test_timer", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_similarity_calculation", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_checksum_generation", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AssertionError: assert False\n        +  where False = <MagicMock name='getLogger().setLevel' id='1915927825104'>.called\n        +    where <MagicMock name='getLogger().setLevel' id='1915927825104'> = <MagicMock name='getLogger()' id='1915927823424'>.setLevel\n", "test_name": "test_logging_setup", "rerun": "0"}}, "status": {"total_pass": 2, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}, "10": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 2, 10, 15, 26, 687333), end_time=datetime.datetime(2025, 4, 2, 10, 15..., successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2025, 4, 2, 10, 15, 26, 687333), end_time=datetime.datetime(2025, 4, 2, 10, 15..., successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file://C:\\\\Users\\\\Andu\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Andu\\\\pytest-10\\\\test_full...t_full_site_crawl0\\\\test_docs/index.html', location=None, details={})], metrics={}, structure=None, processed_url=None).stats\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file://C:\\\\Users\\\\Andu\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Andu\\\\pytest-10\\\\test_cont...processing_pipeli0\\\\test_docs/guide.html', location=None, details={})], metrics={}, structure=None, processed_url=None).documents\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = CrawlResult(target=CrawlTarget(url='file://C:\\\\Users\\\\Andu\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Andu\\\\pytest-10\\\\test_qual...test_quality_checks0\\\\test_docs/api.html', location=None, details={})], metrics={}, structure=None, processed_url=None).metrics\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 2, 10, 16, 4, 115511), end_time=datetime.datetime(2025, 4, 2, 10, 16,..., successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2025, 4, 2, 10, 16, 4, 115511), end_time=datetime.datetime(2025, 4, 2, 10, 16,..., successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file://C:\\\\Users\\\\Andu\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Andu\\\\pytest-10\\\\test_erro...ndling_and_recove0\\\\test_docs/index.html', location=None, details={})], metrics={}, structure=None, processed_url=None).stats\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "11": {"suite_name": "tests/test_integration_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_full_crawl_pipeline", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'str' object has no attribute 'url'\n", "test_name": "test_error_handling_integration", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_rate_limiting_integration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute 'backend'\n", "test_name": "test_content_processing_integration", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}, "12": {"suite_name": "tests/test_link_processor.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 'https://example.com' in ['https://example.com/', 'https://base.com/relative/path', 'https://base.com/parent/path', 'https://base.com/current/path']\n", "test_name": "test_basic_link_extraction", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_empty_document", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_malformed_links", "rerun": "0"}, "3": {"status": "FAIL", "message": "   assert 0 == 1\n    +  where 0 = len([])\n", "test_name": "test_duplicate_links", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 'https://example.com' in ['https://base.com/', 'https://base.com/page.html', 'https://example.com/', 'https://base.com/path']\n", "test_name": "test_fragment_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'https://example.com?param=value' in ['https://base.com/?param=value', 'https://base.com/path?param=value', 'https://example.com/?param=value', 'https://base.com/page.html?param1=value1\u00b6m2=value2']\n", "test_name": "test_query_params", "rerun": "0"}, "6": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_special_characters.<locals>.<genexpr> at 0x000001BE15ACBED0>)\n", "test_name": "test_special_characters", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_nested_links", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_invalid_base_url", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_data_urls", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_unicode_urls", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AssertionError: assert 'https://example.com' in ['https://example.com/', 'https://cdn.example.com/asset.js', 'https://api.example.com/v1']\n", "test_name": "test_protocol_relative_urls", "rerun": "0"}, "12": {"status": "FAIL", "message": "   AssertionError: assert 'https://different-base.com/subdir/relative' in ['https://base.com/relative', 'https://base.com/absolute', 'https://external.com/']\n", "test_name": "test_base_tag_handling", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_malformed_base_tags", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_link_attributes", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AssertionError: assert 'http://example.com' in ['http://example.com/', 'https://example.com/']\n", "test_name": "test_link_schemes", "rerun": "0"}, "16": {"status": "PASS", "message": "", "test_name": "test_url_normalization", "rerun": "0"}, "17": {"status": "FAIL", "message": "   AssertionError: assert ('HTTPS://EXAMPLE.COM' in ['https://base.com/PATH', 'https://base.com/path', 'https://EXAMPLE.COM/', 'https://example.com/', 'https://base.com/Mixed/Case/PATH'] or 'https://example.com' in ['https://base.com/PATH', 'https://base.com/path', 'https://EXAMPLE.COM/', 'https://example.com/', 'https://base.com/Mixed/Case/PATH'])\n", "test_name": "test_url_case_sensitivity", "rerun": "0"}, "18": {"status": "PASS", "message": "", "test_name": "test_url_encoding_handling", "rerun": "0"}}, "status": {"total_pass": 10, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "13": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "14": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'Test Document' == 'Sample Document'\n     \n     - Sample Document\n     + Test Document\n", "test_name": "test_full_content_processing", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert not {'formatted_content': '', 'headings': [], 'structure': []}\n    +  where {'formatted_content': '', 'headings': [], 'structure': []} = ProcessedContent(content={'formatted_content': '', 'structure': [], 'headings': []}, metadata={}, assets={'images': []...ors=['Error processing content: Cleaned content too long: 10008 characters (limit: 10000)'], title='Untitled Document').content\n", "test_name": "test_content_size_limits", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "   assert 0 == 2\n    +  where 0 = len([])\n", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}, "15": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_basic", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_content_length", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_headings", "rerun": "0"}, "3": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_links", "rerun": "0"}, "4": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_code_blocks", "rerun": "0"}, "5": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_metadata", "rerun": "0"}, "6": {"status": "FAIL", "message": "   TypeError: ProcessedContent.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_quality_checker_custom_config", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 7, "total_error": 0}}, "16": {"suite_name": "tests/test_url_handling.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'Exception'>\n", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert <src.utils.url_info.URLInfo object at 0x000001BE16F552E0> == <src.utils.url_info.URLInfo object at 0x000001BE16F551C0>\n", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "FAIL", "message": "       assert True == False\n        +  where True = <src.utils.url_info.URLInfo object at 0x000001BE16F78320>.is_valid\n", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'. Did you mean: 'normalized_url'?\n", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_url_info_performance", "rerun": "0"}}, "status": {"total_pass": 2, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 13, "total_error": 0}}}}, "date": "April 02, 2025", "start_time": 1743588973.5869622, "total_suite": 17, "status": "FAIL", "status_list": {"pass": "53", "fail": "136", "skip": "0", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "189"}