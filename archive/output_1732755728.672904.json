{"content": {"suites": {"0": {"status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "FAIL", "message": "       TypeError: URLProcessor() takes no arguments\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for ProcessedContent\n   url\n     Field required [type=missing, input_value={'title': 'Test Document'...est', 'language': 'en'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'dict' object has no attribute 'total_requests'\n", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_content_processor_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 'Main Title' in ProcessedContent(url='', title='Test Page', content={'title': 'Test Page', 'formatted_content': '', 'headings': [{'lev... 'code_blocks': [{'language': '', 'content': 'def test(): pass'}], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_basic_html_processing", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'def example():' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'h...ontent': 'def example():\\n    return Truefunction test() {\\n    return true;\\n}'}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_code_block_extraction", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'Header 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '| Hea...l 3 | Cell 4 |\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_table_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('* Item 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '- Ite...t\\n2. Second\\n\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[]) or '- Item 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '- Ite...t\\n2. Second\\n\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[]))\n", "test_name": "test_list_processing", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 'Example Link' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'h...nk', 'type': 'internal', 'source': 'content'}], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'Test Image' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_image_processing", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert '# Main Title' in ProcessedContent(url='', title='Main Title', content={'title': 'Main Title', 'formatted_content': '\\n# Main Title\\n\\n\\...tent': []}, {'type': 'section', 'level': 4, 'title': 'Subsection', 'content': []}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_heading_hierarchy", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert ('\u00a9' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '\u00a9 202...le>'}, {'type': 'text', 'content': '\u20ac symbol'}, {'type': 'text', 'content': '\u6f22\u5b57'}]}, metadata={}, assets={}, errors=[]) or '(c)' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '\u00a9 202...le>'}, {'type': 'text', 'content': '\u20ac symbol'}, {'type': 'text', 'content': '\u6f22\u5b57'}]}, metadata={}, assets={}, errors=[]))\n", "test_name": "test_special_characters", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Valid content' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'h...[], 'code_blocks': [], 'structure': [{'type': 'text', 'content': 'Valid content'}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_content_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   TypeError: object of type 'ProcessedContent' has no len()\n", "test_name": "test_performance", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert False\n        +  where False = isinstance(ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': 'Unclo...code_blocks': [], 'structure': [{'type': 'text', 'content': 'Unclosed paragraph'}]}, metadata={}, assets={}, errors=[]), str)\n", "test_name": "test_error_handling", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute 'extract_metadata'\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "12": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor_normalization", "rerun": "0"}, "13": {"status": "FAIL", "message": "   assert <URLType.UNKNOWN: 'unknown'> == <URLType.INTERNAL: 'internal'>\n    +  where <URLType.UNKNOWN: 'unknown'> = URLInfo(raw_url='http://example.com/docs', normalized_url='http://example.com/docs', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").url_type\n    +  and   <URLType.INTERNAL: 'internal'> = URLType.INTERNAL\n", "test_name": "test_url_type_detection", "rerun": "0"}, "14": {"status": "FAIL", "message": "   assert False\n    +  where False = URLInfo(raw_url='http://example.com', normalized_url='http://example.com', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_validation", "rerun": "0"}, "15": {"status": "FAIL", "message": "   assert False\n    +  where False = URLInfo(raw_url='http://example.com/path with spaces/', normalized_url='http://example.com/path with spaces/', url_typ...NOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_edge_cases", "rerun": "0"}, "16": {"status": "PASS", "message": "", "test_name": "test_url_processor_security", "rerun": "0"}, "17": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://m\u00fcnchen.de', normalized_url='http://m\u00fcnchen.de', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_international", "rerun": "0"}, "18": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='./page', normalized_url='./page', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_relative_paths", "rerun": "0"}, "19": {"status": "FAIL", "message": "       assert <URLType.UNKNOWN: 'unknown'> == <URLType.ASSET: 'asset'>\n        +  where <URLType.UNKNOWN: 'unknown'> = URLInfo(raw_url='http://example.com/image.jpg', normalized_url='http://example.com/image.jpg', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").url_type\n", "test_name": "test_url_processor_asset_types", "rerun": "0"}, "20": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com/?a=1&b=2', normalized_url='http://example.com/?a=1&b=2', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_query_handling", "rerun": "0"}, "21": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com', normalized_url='http://example.com', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_scheme_handling", "rerun": "0"}, "22": {"status": "FAIL", "message": "           assert False\n            +  where False = URLInfo(raw_url='http://example.com:80', normalized_url='http://example.com:80', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_port_handling", "rerun": "0"}, "23": {"status": "FAIL", "message": "           assert 'authentication' in \"url normalization failed: name 'idna' is not defined\"\n            +  where \"url normalization failed: name 'idna' is not defined\" = <built-in method lower of str object at 0x11f4bf520>()\n            +    where <built-in method lower of str object at 0x11f4bf520> = \"URL normalization failed: name 'idna' is not defined\".lower\n            +      where \"URL normalization failed: name 'idna' is not defined\" = URLInfo(raw_url='http://user:pass@example.com', normalized_url='http://user:pass@example.com', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").error_msg\n", "test_name": "test_url_processor_auth_handling", "rerun": "0"}, "24": {"status": "FAIL", "message": "           assert False\n            +  where False = any(<generator object test_url_processor_ip_handling.<locals>.<genexpr> at 0x138930660>)\n", "test_name": "test_url_processor_ip_handling", "rerun": "0"}, "25": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com/caf\u00e9', normalized_url='http://example.com/caf\u00e9', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_unicode_normalization", "rerun": "0"}, "26": {"status": "FAIL", "message": "           assert 'domain' in \"url normalization failed: name 'idna' is not defined\"\n            +  where \"url normalization failed: name 'idna' is not defined\" = <built-in method lower of str object at 0x11f4bf520>()\n            +    where <built-in method lower of str object at 0x11f4bf520> = \"URL normalization failed: name 'idna' is not defined\".lower\n            +      where \"URL normalization failed: name 'idna' is not defined\" = URLInfo(raw_url='http://example', normalized_url='http://example', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").error_msg\n", "test_name": "test_url_processor_domain_validation", "rerun": "0"}, "27": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com/normal/path', normalized_url='http://example.com/normal/path', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_path_validation", "rerun": "0"}, "28": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com?normal=value', normalized_url='http://example.com?normal=value', url_type=<URLType...NOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_query_validation", "rerun": "0"}, "29": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com#section', normalized_url='http://example.com#section', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_fragment_handling", "rerun": "0"}, "30": {"status": "FAIL", "message": "   NameError: name 'RateLimiter' is not defined\n", "test_name": "test_rate_limiter", "rerun": "0"}, "31": {"status": "FAIL", "message": "   NameError: name 'RetryStrategy' is not defined\n", "test_name": "test_retry_strategy", "rerun": "0"}, "32": {"status": "FAIL", "message": "   NameError: name 'calculate_similarity' is not defined\n", "test_name": "test_calculate_similarity", "rerun": "0"}, "33": {"status": "FAIL", "message": "   NameError: name 'generate_checksum' is not defined\n", "test_name": "test_generate_checksum", "rerun": "0"}, "34": {"status": "PASS", "message": "", "test_name": "test_timer", "rerun": "0"}, "35": {"status": "FAIL", "message": "   NameError: name 'setup_logging' is not defined\n", "test_name": "test_setup_logging", "rerun": "0"}, "36": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor_normalize_url", "rerun": "0"}, "37": {"status": "FAIL", "message": "   AssertionError: assert <URLType.EXTERNAL: 'external'> == <URLType.INTERNAL: 'internal'>\n    +  where <URLType.EXTERNAL: 'external'> = <bound method URLProcessor._determine_url_type of <class 'src.utils.helpers.URLProcessor'>>('/page', 'http://example.com')\n    +    where <bound method URLProcessor._determine_url_type of <class 'src.utils.helpers.URLProcessor'>> = <src.utils.helpers.URLProcessor object at 0x11f763b90>._determine_url_type\n    +  and   <URLType.INTERNAL: 'internal'> = URLType.INTERNAL\n", "test_name": "test_url_processor_determine_type", "rerun": "0"}, "38": {"status": "FAIL", "message": "   NameError: name 'RateLimiter' is not defined\n", "test_name": "test_rate_limiter_wait", "rerun": "0"}, "39": {"status": "FAIL", "message": "   assert False\n    +  where False = URLInfo(raw_url='http://example.com/page', normalized_url='http://example.com/page', url_type=<URLType.UNKNOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_process_url", "rerun": "0"}, "40": {"status": "FAIL", "message": "       NameError: name 'time' is not defined\n", "test_name": "test_timer_duration", "rerun": "0"}}, "status": {"total_pass": 2, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 39, "total_error": 0}}, "2": {"suite_name": "tests/test_content_processor_edge.py", "tests": {"0": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'src.processors.content_processor.ContentProcessingError'>\n", "test_name": "test_empty_content", "rerun": "0"}, "1": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_malformed_html", "rerun": "0"}, "2": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_special_characters", "rerun": "0"}, "3": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_large_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_nested_structures", "rerun": "0"}, "5": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_javascript_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_style_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_iframe_handling", "rerun": "0"}, "8": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_form_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "3": {"suite_name": "tests/test_crawl4ai.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_basic", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawl_with_rate_limit", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_validate_content", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('content' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. Y...in in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'} or 'error' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. Y...in in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'})\n", "test_name": "test_process_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_backend_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metrics", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 == 500\n    +  where 0 = CrawlResult(url='https://invalid-url-that-does-not-exist.com', content={}, metadata={}, status=0, error='Failed after ...:default [nodename nor servname provided, or not known]', timestamp=datetime.datetime(2024, 11, 28, 0, 55, 48, 224793)).status\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_concurrent_requests", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_crawl4ai_config_validation", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_ssl_context_configuration", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_custom_headers_handling", "rerun": "0"}, "12": {"status": "FAIL", "message": "   assert 200 == 403\n    +  where 200 = CrawlResult(url='https://other-domain.com/page', content={'html': '<!DOCTYPE html>\\n<html lang=\"ja\">\\n<head>\\n\\t<meta ...e': 'text/html; charset=UTF-8'}}, status=200, error=None, timestamp=datetime.datetime(2024, 11, 28, 0, 55, 48, 224793)).status\n", "test_name": "test_domain_filtering", "rerun": "0"}, "13": {"status": "FAIL", "message": "   AssertionError: assert 5 == 3\n    +  where 5 = len([CrawlResult(url='https://example.com/page0', content={'html': '<!doctype html>\\n<html>\\n<head>\\n    <title>Example Do...HIT', 'Content-Length': '648'}}, status=404, error=None, timestamp=datetime.datetime(2024, 11, 28, 0, 55, 48, 224793))])\n", "test_name": "test_url_queue_management", "rerun": "0"}}, "status": {"total_pass": 8, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "4": {"suite_name": "tests/test_crawl4ai_extended.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_crawl_with_urlinfo", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'requests'\n", "test_name": "test_crawl_depth_first", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert False\n    +  where False = all(<generator object test_rate_limiting_precision.<locals>.<genexpr> at 0x138bf4110>)\n", "test_name": "test_rate_limiting_precision", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_concurrent_request_limit", "rerun": "0"}, "4": {"status": "FAIL", "message": "           TypeError: URLInfo.__init__() got an unexpected keyword argument 'url'\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "           assert 0 == 500\n            +  where 0 = CrawlResult(url='https://nonexistent.example.com', content={}, metadata={}, status=0, error=\"Failed after 2 retries: '...s not support the asynchronous context manager protocol\", timestamp=datetime.datetime(2024, 11, 28, 0, 55, 48, 224793)).status\n", "test_name": "test_error_propagation", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'get'\n", "test_name": "test_retry_behavior", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_metrics_accuracy", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'closed'\n", "test_name": "test_resource_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() missing 5 required positional arguments: 'normalized_url', 'url_type', 'domain', 'path', and 'is_valid'\n", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "10": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() missing 5 required positional arguments: 'normalized_url', 'url_type', 'domain', 'path', and 'is_valid'\n", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "11": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() missing 5 required positional arguments: 'normalized_url', 'url_type', 'domain', 'path', and 'is_valid'\n", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}, "12": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() missing 5 required positional arguments: 'normalized_url', 'url_type', 'domain', 'path', and 'is_valid'\n", "test_name": "test_url_info_hashable", "rerun": "0"}, "13": {"status": "FAIL", "message": "   TypeError: URLInfo.__init__() missing 5 required positional arguments: 'normalized_url', 'url_type', 'domain', 'path', and 'is_valid'\n", "test_name": "test_url_info_immutable", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 13, "total_error": 0}}, "5": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert not True\n    +  where True = <bound method DocumentationCrawler._should_crawl_url of <src.crawler.DocumentationCrawler object at 0x138c0ae50>>('https://example.com/excluded/page', CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=['/excluded/'], required_patterns=['/doc'], max_pages=10, allowed_paths=[], excluded_paths=[]))\n    +    where <bound method DocumentationCrawler._should_crawl_url of <src.crawler.DocumentationCrawler object at 0x138c0ae50>> = <src.crawler.DocumentationCrawler object at 0x138c0ae50>._should_crawl_url\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 775374), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 775374), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=2, follow_external=False, content_types=['text/ht...es not support the asynchronous context manager protocol\", rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 791863), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).failed_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 791863), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://invalid.example.com', depth=1, follow_external=False, content_types=['text...es not support the asynchronous context manager protocol\", rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 == 1\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 799131), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 799131), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=1, follow_external=False, content_types=['text/ht...es not support the asynchronous context manager protocol\", rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert None is not None\n    +  where None = <src.crawler.DocumentationCrawler object at 0x138c98bd0>.client_session\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "   assert None is not None\n    +  where None = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 845981), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).end_time\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 8, 845981), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=1, follow_external=False, content_types=['text/ht...es not support the asynchronous context manager protocol\", rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_statistics_tracking", "rerun": "0"}, "11": {"status": "FAIL", "message": "   NameError: name 'ProjectType' is not defined\n", "test_name": "test_project_type_enum", "rerun": "0"}, "12": {"status": "FAIL", "message": "   NameError: name 'ProjectIdentity' is not defined\n", "test_name": "test_project_identity", "rerun": "0"}, "13": {"status": "FAIL", "message": "   NameError: name 'ProjectIdentifier' is not defined\n", "test_name": "test_project_identifier", "rerun": "0"}, "14": {"status": "FAIL", "message": "   NameError: name 'DUCKDUCKGO_AVAILABLE' is not defined\n", "test_name": "test_duckduckgo_search", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute '_discover_urls'\n", "test_name": "test_url_discovery", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'ProjectIdentifier' object has no attribute '_identify_project_type'\n", "test_name": "test_project_type_detection", "rerun": "0"}}, "status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 14, "total_error": 0}}, "6": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246347984'>\nmock_content_processor = <AsyncMock id='5246726224'>\nmock_quality_checker = <AsyncMock id='5246626000'>\nmock_document_organizer = <AsyncMock id='4825154128'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138b76710>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246347984'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5245554320'>\nmock_content_processor = <AsyncMock id='5242605712'>\nmock_quality_checker = <AsyncMock id='5245046096'>\nmock_document_organizer = <AsyncMock id='5245599632'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138b93b50>\nbackend = <AsyncMock spec='CrawlerBackend' id='5245554320'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5247707344'>\nmock_content_processor = <AsyncMock id='5244738576'>\nmock_quality_checker = <AsyncMock id='5245572624'>\nmock_document_organizer = <AsyncMock id='5246373328'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x11f9a2f10>\nbackend = <AsyncMock spec='CrawlerBackend' id='5247707344'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246412240'>\nmock_content_processor = <AsyncMock id='5245531088'>\nmock_quality_checker = <AsyncMock id='5245007568'>\nmock_document_organizer = <AsyncMock id='5246756432'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138c15fd0>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246412240'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246185296'>\nmock_content_processor = <AsyncMock id='4824734928'>\nmock_quality_checker = <AsyncMock id='5246379920'>\nmock_document_organizer = <AsyncMock id='5244746512'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138b4d910>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246185296'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5244687696'>\nmock_content_processor = <AsyncMock id='5247609936'>\nmock_quality_checker = <AsyncMock id='5247093840'>\nmock_document_organizer = <AsyncMock id='5247255056'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138b7ec50>\nbackend = <AsyncMock spec='CrawlerBackend' id='5244687696'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246659920'>\nmock_content_processor = <AsyncMock id='5246223248'>\nmock_quality_checker = <AsyncMock id='5244736976'>\nmock_document_organizer = <AsyncMock id='5247285904'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138b4fb10>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246659920'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246596688'>\nmock_content_processor = <AsyncMock id='5247639568'>\nmock_quality_checker = <AsyncMock id='5247232464'>\nmock_document_organizer = <AsyncMock id='5246506064'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138bf3150>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246596688'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246184336'>\nmock_content_processor = <AsyncMock id='5247588112'>\nmock_quality_checker = <AsyncMock id='5247590032'>\nmock_document_organizer = <AsyncMock id='5246228368'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138c33ad0>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246184336'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5246347472'>\nmock_content_processor = <AsyncMock id='5246720912'>\nmock_quality_checker = <AsyncMock id='5247835216'>\nmock_document_organizer = <AsyncMock id='5247575824'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x138c7a450>\nbackend = <AsyncMock spec='CrawlerBackend' id='5246347472'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 10}}, "7": {"suite_name": "tests/test_gui.py", "tests": {"0": {"status": "FAIL", "message": "       jinja2.exceptions.TemplateNotFound: index.html\n", "test_name": "test_home_page", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'error' == 'success'\n     \n     - success\n     + error\n", "test_name": "test_crawl_request", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_connection_manager", "rerun": "0"}, "3": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for ProcessedContent\n   title\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   content\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_crawler_thread", "rerun": "0"}, "4": {"status": "FAIL", "message": "   NameError: name 'ResultsViewer' is not defined\n", "test_name": "test_results_viewer", "rerun": "0"}, "5": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for ProcessedContent\n   title\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   content\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_save_results", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: Expected 'critical' to have been called once. Called 0 times.\n       AssertionError: Expected 'critical' to have been called once. Called 0 times.\n", "test_name": "test_error_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "8": {"suite_name": "tests/test_helpers.py", "tests": {"0": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'RateLimiter' object has no attribute 'delay'\n", "test_name": "test_rate_limiter", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: RetryStrategy.__init__() got an unexpected keyword argument 'base_delay'\n", "test_name": "test_retry_strategy", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'Timer' object has no attribute 'elapsed'\n", "test_name": "test_timer", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 0.7777777777777778 > 0.8\n    +  where 0.7777777777777778 = calculate_similarity('This is a test document about Python programming', 'This is a test document about Python coding')\n", "test_name": "test_similarity_calculation", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_checksum_generation", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: assert None == <MagicMock name='getLogger()' id='5247246032'>\n", "test_name": "test_logging_setup", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "9": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 11, 215908), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 11, 215908), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pyt...ex/pytest-103/test_full_site_crawl0/test_docs/index.html', rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pyt...103/test_content_processing_pipeli0/test_docs/guide.html', rule_name='general', location='', metadata={})], metrics={}).documents\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pyt...-alex/pytest-103/test_quality_checks0/test_docs/api.html', rule_name='general', location='', metadata={})], metrics={}).metrics\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 13, 645519), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 28, 0, 58, 13, 645519), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pyt...103/test_error_handling_and_recove0/test_docs/index.html', rule_name='general', location='', metadata={})], metrics={}).stats\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "10": {"suite_name": "tests/test_integration_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_full_crawl_pipeline", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute 'backend'\n", "test_name": "test_error_handling_integration", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_rate_limiting_integration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute 'backend'\n", "test_name": "test_content_processing_integration", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}, "11": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = DocumentMetadata(title='Test Document', url='https://example.com/doc', category='reference', tags=['document', 'versio...l': [], 'code': []}, index_terms=['document', 'test'], last_updated=datetime.datetime(2024, 11, 28, 2, 58, 14, 131682)).versions\n", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'example' is None\n    +  where 'example' = DocumentMetadata(title='Miscellaneous', url='https://example.com/misc', category='example', tags=['miscellaneous', 'co...rnal': [], 'code': []}, index_terms=['miscellaneous'], last_updated=datetime.datetime(2024, 11, 28, 2, 58, 14, 136907)).category\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_search_index_generation.<locals>.<genexpr> at 0x138c3cac0>)\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 4, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "12": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_clean_text_processing", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_code_language_detection", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'text' == 'python'\n     \n     - python\n     + text\n", "test_name": "test_code_block_processing", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'keywords' in {'description': 'Test description'}\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "6": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_asset_collection", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert 'Test Document' == 'Sample Document'\n     \n     - Sample Document\n     + Test Document\n", "test_name": "test_full_content_processing", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Content exceeds maximum size limit' in ['Content size (10034) exceeds limit (10000)']\n    +  where ['Content size (10034) exceeds limit (10000)'] = ProcessedContent(url='https://example.com', title='Content Too Large', content={}, metadata={}, assets={}, errors=['Content size (10034) exceeds limit (10000)']).errors\n", "test_name": "test_content_size_limits", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "13": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'content_le...nt too short: 21 chars'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'heading_st...cument has no headings'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'link_valid...://invalid.example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'metadata_c...ds, title, description'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'code_block...t': 'def test(): pass'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_quality_issue_initialization", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_quality_issue_location_handling", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_issue_metadata", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "10": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n   type\n     Field required [type=missing, input_value={'rule_name': 'link_valid...ps://example.com/valid'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_full_quality_check", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 6, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "14": {"suite_name": "tests/test_url_handling.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'Exception'>\n", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "FAIL", "message": "   TypeError: unhashable type: 'URLInfo'\n", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "FAIL", "message": "       AttributeError: 'URLInfo' object has no attribute 'normalized'\n", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example0.com/path/to/page?param=0', normalized_url='http://example0.com/path/to/page?param=0',...NOWN: 'unknown'>, domain='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_info_performance", "rerun": "0"}}, "status": {"total_pass": 2, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 13, "total_error": 0}}}}, "date": "November 28, 2024", "start_time": 1732755494.9320252, "total_suite": 15, "status": "FAIL", "status_list": {"pass": "39", "fail": "137", "skip": "0", "error": "10", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "186"}