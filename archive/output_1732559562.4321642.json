{"content": {"suites": {"0": {"status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert False\n    +  where False = URLInfo(original='https://example.com/path?q=test', normalized='https://example.com/path?q=test', scheme='https', netloc='example.com', path='/path', is_valid=False).is_valid\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert False\n    +  where False = _should_crawl_url('https://example.com/doc1', CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=['/excluded/'], required_patterns=['/doc'], max_pages=10))\n    +    where _should_crawl_url = <src.crawler.DocumentationCrawler object at 0x106e0acd0>._should_crawl_url\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186380), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186706), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186380), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186706), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186380), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 186706), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 0 == 3\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 18, 31, 16, 189824), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +  and   3 = len({'https://example.com/doc1', 'https://example.com/doc2', 'https://example.com/doc3'})\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405474), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405617), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).failed_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405474), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405617), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://invalid.example.com', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405474), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 405617), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 408955), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 409173), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 408955), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 409173), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc1', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 408955), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 409173), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert <aiohttp.client.ClientSession object at 0x106d98210> is None\n    +  where <aiohttp.client.ClientSession object at 0x106d98210> = <src.crawler.DocumentationCrawler object at 0x106ddf3d0>.client_session\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AssertionError: assert 0.0 > 0\n    +  where 0.0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 417978), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 418134), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).total_time\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 417978), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 418134), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc1', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=3), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 417978), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 418134), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_statistics_tracking", "rerun": "0"}}, "status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "2": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 423783), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 424024), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 423783), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 424024), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-21/test_full_site_crawl0/test_docs/index.html', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['.html'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 423783), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 424024), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-21/test_content_processing_pipeli0/test_docs/guide.html', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 428456), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 428609), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).documents\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-21/test_quality_checks0/test_docs/api.html', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 432727), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 432895), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).metrics\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442433), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442579), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442433), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442579), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-21/test_error_handling_and_recove0/test_docs/index.html', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['.html', '.invalid'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442433), end_time=datetime.datetime(2024, 11, 25, 20, 31, 16, 442579), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "3": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'example' == 'uncategorized'\n     \n     - uncategorized\n     + example\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'code' in {'external': ['https://external.com'], 'internal': ['https://example.com/internal']}\n", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = <src.organizers.doc_organizer.DocumentOrganizer object at 0x106e58610>.search_indices\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 6, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}, "4": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   NameError: name 'ProcessingRule' is not defined\n", "test_name": "test_processing_rule_validation", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_clean_text'\n", "test_name": "test_clean_text_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_extract_code_language'\n", "test_name": "test_code_language_detection", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_process_code_blocks'\n", "test_name": "test_code_block_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_process_links'\n", "test_name": "test_link_processing", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_extract_metadata'\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_collect_assets'\n", "test_name": "test_asset_collection", "rerun": "0"}, "8": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'assets'\n", "test_name": "test_full_content_processing", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AssertionError: assert not {'code_blocks': [], 'headings': [], 'links': [], 'text': 'xxxxxxxxx'}\n    +  where {'code_blocks': [], 'headings': [], 'links': [], 'text': 'xxxxxxxxx'} = ProcessedContent(url='https://example.com', title='Untitled Document', content={'headings': [], 'code_blocks': [], 'links': [], 'text': 'xxxxxxxxx'}, errors=[]).content\n", "test_name": "test_content_size_limits", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 4, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "5": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'metadata'\n", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'metadata'\n", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'assets'\n", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "7": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'metadata'\n", "test_name": "test_full_quality_check", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 5, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}}}, "date": "November 25, 2024", "start_time": 1732559476.9184341, "total_suite": 6, "status": "FAIL", "status_list": {"pass": "26", "fail": "31", "skip": "0", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "57"}