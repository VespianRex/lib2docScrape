{"content": {"suites": {"0": {"status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert False\n    +  where False = URLInfo(original='https://example.com/path?q=test', normalized='https://example.com/path?q=test', scheme='https', netloc='example.com', path='/path', is_valid=False).is_valid\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert False\n    +  where False = _should_crawl_url('https://example.com/doc1', CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=['/excluded/'], required_patterns=['/doc'], max_pages=10))\n    +    where _should_crawl_url = <src.crawler.DocumentationCrawler object at 0x11120b310>._should_crawl_url\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225642), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225815), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225642), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225815), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225642), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 225815), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 0 == 3\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 18, 32, 40, 229382), end_time=None, pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +  and   3 = len({'https://example.com/doc1', 'https://example.com/doc2', 'https://example.com/doc3'})\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233812), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233917), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).failed_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233812), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233917), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://invalid.example.com', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233812), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 233917), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237276), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237374), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237276), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237374), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237276), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 237374), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert <aiohttp.client.ClientSession object at 0x1110e60d0> is None\n    +  where <aiohttp.client.ClientSession object at 0x1110e60d0> = <src.crawler.DocumentationCrawler object at 0x11119b550>.client_session\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AssertionError: assert 0.0 > 0\n    +  where 0.0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 244932), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 245022), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).total_time\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 244932), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 245022), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='https://example.com/doc2', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=3), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 244932), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 245022), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_statistics_tracking", "rerun": "0"}}, "status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "2": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 250878), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 251016), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 250878), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 251016), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-22/test_full_site_crawl0/test_docs/index.html', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['.html'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 250878), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 251016), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-22/test_content_processing_pipeli0/test_docs/guide.html', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 255527), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 255601), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).documents\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-22/test_quality_checks0/test_docs/api.html', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=1), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 259467), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 259550), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).metrics\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269129), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269231), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269129), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269231), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-22/test_error_handling_and_recove0/test_docs/index.html', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['.html', '.invalid'], max_pages=10), stats=CrawlStats(start_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269129), end_time=datetime.datetime(2024, 11, 25, 20, 32, 40, 269231), pages_crawled=0, successful_crawls=0, failed_crawls=0, total_time=0.0, average_time_per_page=0.0, quality_issues=0, bytes_processed=0), documents=[], issues=[], metrics={}).stats\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "3": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'example' == 'uncategorized'\n     \n     - uncategorized\n     + example\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'code' in {'external': ['https://external.com'], 'internal': ['https://example.com/internal']}\n", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = <src.organizers.doc_organizer.DocumentOrganizer object at 0x111257110>.search_indices\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 6, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}, "4": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   NameError: name 'ProcessingRule' is not defined\n", "test_name": "test_processing_rule_validation", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: ContentProcessor._clean_text() got an unexpected keyword argument 'clean_regex'\n", "test_name": "test_clean_text_processing", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_code_language_detection", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 'metadata' in {'content': 'def hello():\\n                print(\"Hello, World!\")', 'language': 'python'}\n", "test_name": "test_code_block_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'type' in {'text': 'link', 'title': '', 'url': 'https://example.com'}\n", "test_name": "test_link_processing", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_metadata_extraction", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_asset_collection", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n    +    where [] = <built-in method get of dict object at 0x11127c480>('images', [])\n    +      where <built-in method get of dict object at 0x11127c480> = {}.get\n    +        where {} = ProcessedContent(url='https://example.com/test', title='Sample Document', content={'headings': [{'level': 1, 'text': 'Main Title'}, {'level': 2, 'text': 'Section 1'}], 'code_blocks': [{'language': 'text', 'content': 'def hello():\\n                print(\"Hello, World!\")'}, {'language': 'language-python', 'content': 'def hello():\\n                print(\"Hello, World!\")'}], 'links': [{'url': 'https://example.com', 'text': 'link', 'title': ''}], 'text': 'Sample Document\\n\\n\\n\\n\\nMain Title\\nFirst paragraph with link.\\nSection 1\\nSecond paragraph.\\n\\n            def hello():\\n                print(\"Hello, World!\")\\n            \\n\\nItem 1\\nItem 2'}, metadata={}, assets={}, errors=[]).assets\n", "test_name": "test_full_content_processing", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AssertionError: assert not {'code_blocks': [], 'headings': [], 'links': [], 'text': 'xxxxxxxxx'}\n    +  where {'code_blocks': [], 'headings': [], 'links': [], 'text': 'xxxxxxxxx'} = ProcessedContent(url='https://example.com', title='Untitled Document', content={'headings': [], 'code_blocks': [], 'links': [], 'text': 'xxxxxxxxx'}, metadata={}, assets={}, errors=[]).content\n", "test_name": "test_content_size_limits", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "5": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_full_quality_check", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 9, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 0}}}}, "date": "November 25, 2024", "start_time": 1732559562.4321642, "total_suite": 6, "status": "FAIL", "status_list": {"pass": "33", "fail": "24", "skip": "0", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "57"}