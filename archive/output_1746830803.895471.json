{"content": {"suites": {"0": {"status": {"total_pass": 11, "total_skip": 1, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_target_stability", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 1 == 2\n    +  where 1 = CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 382028, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 415653, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=1, failed_crawls=0, total_time=0.033625, average_time_per_page=0.033625, quality_issues=1, bytes_processed=160).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 382028, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 415653, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=1, failed_crawls=0, total_time=0.033625, average_time_per_page=0.033625, quality_issues=1, bytes_processed=160) = CrawlResult(target=CrawlTarget(url='http://example.com', depth=1, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=None, allowed_paths=[], excluded_paths=[]), stats=CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 382028, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 415653, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=1, failed_crawls=0, total_time=0.033625, average_time_per_page=0.033625, quality_issues=1, bytes_processed=160), documents=[{'url': 'http://example.com', 'title': 'Mock Title', 'content': {'formatted_content': 'Processed content', 'structure': []}, 'metadata': {'title': 'Mock Title'}, 'assets': {'images': [], 'stylesheets': [], 'scripts': [], 'media': []}}], issues=[QualityIssue(type=<IssueType.GENERAL: 'general'>, level=<IssueLevel.WARNING: 'warning'>, message='Low content quality', location='body', details={})], metrics={'http://example.com': {'quality_score': 0.5}}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={'http://example.com': ProcessedContent(url='http://example.com', content={'formatted_content': 'Processed content', 'structure': []}, metadata={'title': 'Mock Title'}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, headings=[], structure=[], errors=[], title='Mock Title')}).stats\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 1 == 0\n    +  where 1 = CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 450567, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 20, 469389, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=0, failed_crawls=1, total_time=3.018822, average_time_per_page=3.018822, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 450567, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 20, 469389, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=0, failed_crawls=1, total_time=3.018822, average_time_per_page=3.018822, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='http://nonexistent.com', depth=0, follow_external=False, content_types=['text/html'], exclude_patterns=[], required_patterns=['/3/'], max_pages=None, allowed_paths=[], excluded_paths=[]), stats=CrawlStats(start_time=datetime.datetime(2025, 5, 9, 22, 45, 17, 450567, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 5, 9, 22, 45, 20, 469389, tzinfo=datetime.timezone.utc), pages_crawled=1, successful_crawls=0, failed_crawls=1, total_time=3.018822, average_time_per_page=3.018822, quality_issues=0, bytes_processed=0), documents=[], issues=[QualityIssue(type=<IssueType.GENERAL: 'general'>, level=<IssueLevel.ERROR: 'error'>, message='Failed after retries: Exception(Status 404: Not Found)', location=None, details={})], metrics={}, structure=None, processed_url=None, failed_urls=['http://nonexistent.com'], errors={'http://nonexistent.com': Exception('Status 404: Not Found')}, crawled_pages={}).stats\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "4": {"status": "SKIP", "message": "('/home/alex/DEV/lib2docScrape/tests/test_crawler_advanced.py', 239, 'Skipped: Rate limiter timing is difficult to test reliably with mocks')\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_crawler_content_processing", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_crawler_error_handling[error0-Network error]", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_crawler_error_handling[error1-Invalid response]", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_crawler_error_handling[error2-Timeout]", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_crawler_error_handling[error3-Connection failed]", "rerun": "0"}}, "suite_name": "tests/test_crawler_advanced.py"}}}, "date": "May 10, 2025", "start_time": 1746830732.7197814, "total_suite": 1, "status": "FAIL", "status_list": {"pass": "11", "fail": "2", "skip": "1", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "14"}