{"content": {"suites": {"0": {"status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'crawl4ai' == 'MockCrawlerBackend'\n     \n     - MockCrawlerBackend\n     + crawl4ai\n", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_content_processor_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_basic_html_processing", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_code_block_extraction", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_table_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_list_processing", "rerun": "0"}, "4": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_image_processing", "rerun": "0"}, "6": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_heading_hierarchy", "rerun": "0"}, "7": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_special_characters", "rerun": "0"}, "8": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_content_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "       TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_performance", "rerun": "0"}, "10": {"status": "FAIL", "message": "       TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_error_handling", "rerun": "0"}, "11": {"status": "FAIL", "message": "   TypeError: ContentProcessor.process() missing 1 required positional argument: 'url'\n", "test_name": "test_metadata_extraction", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 12, "total_error": 0}}, "2": {"suite_name": "tests/test_crawl4ai.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_basic", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawl_with_rate_limit", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_validate_content", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('content' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'} or 'error' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'})\n", "test_name": "test_process_content", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_backend_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metrics", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 == 500\n    +  where 0 = CrawlResult(url='https://invalid-url-that-does-not-exist.com', content={}, metadata={}, status=0, error='Failed after 2 retries: Cannot connect to host invalid-url-that-does-not-exist.com:443 ssl:default [nodename nor servname provided, or not known]').status\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_concurrent_requests", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_cleanup", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}}, "3": {"suite_name": "tests/test_crawl4ai_extended.py", "tests": {"0": {"status": "FAIL", "message": "   assert 0 == 200\n    +  where 0 = CrawlResult(url='https://example.com/', content={}, metadata={}, status=0, error=\"Failed after 2 retries: 'coroutine' object does not support the asynchronous context manager protocol\").status\n", "test_name": "test_crawl_with_urlinfo", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'requests'\n", "test_name": "test_crawl_depth_first", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert False\n    +  where False = all(<generator object test_rate_limiting_precision.<locals>.<genexpr> at 0x106159560>)\n", "test_name": "test_rate_limiting_precision", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_concurrent_request_limit", "rerun": "0"}, "4": {"status": "FAIL", "message": "           AssertionError: assert 'https://example.com/' == 'https://example.com'\n             \n             - https://example.com\n             + https://example.com/\n             ?                    +\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "           assert 0 == 500\n            +  where 0 = CrawlResult(url='https://nonexistent.example.com', content={}, metadata={}, status=0, error=\"Failed after 2 retries: 'coroutine' object does not support the asynchronous context manager protocol\").status\n", "test_name": "test_error_propagation", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'get'\n", "test_name": "test_retry_behavior", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_metrics_accuracy", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'closed'\n", "test_name": "test_resource_cleanup", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AssertionError: assert 'http://invalid-url' == 'invalid-url'\n     \n     - invalid-url\n     + http://invalid-url\n     ? +++++++\n", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_url_info_hashable", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_url_info_immutable", "rerun": "0"}}, "status": {"total_pass": 5, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "4": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert not True\n    +  where True = _should_crawl_url('https://example.com/excluded/page', CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=['/excluded/'], required_patterns=['/doc'], max_pages=10, allowed_paths=[], excluded_paths=[]))\n    +    where _should_crawl_url = <src.crawler.DocumentationCrawler object at 0x106140ed0>._should_crawl_url\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"'Timer' object does not ...ontext manager protocol\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_statistics_tracking", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 10, "total_error": 0}}, "5": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4423439568'>\nmock_content_processor = <AsyncMock id='4423446800'>\nmock_quality_checker = <AsyncMock id='4397754832'>\nmock_document_organizer = <AsyncMock id='4423231120'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1063ba450>\nbackend = <AsyncMock spec='CrawlerBackend' id='4423439568'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4399593552'>\nmock_content_processor = <AsyncMock id='4423186640'>\nmock_quality_checker = <AsyncMock id='4423543184'>\nmock_document_organizer = <AsyncMock id='4423541392'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1061c7310>\nbackend = <AsyncMock spec='CrawlerBackend' id='4399593552'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4423412048'>\nmock_content_processor = <AsyncMock id='4423401872'>\nmock_quality_checker = <AsyncMock id='4397194064'>\nmock_document_organizer = <AsyncMock id='4397085136'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106142590>\nbackend = <AsyncMock spec='CrawlerBackend' id='4423412048'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4397147984'>\nmock_content_processor = <AsyncMock id='4397330640'>\nmock_quality_checker = <AsyncMock id='4423058640'>\nmock_document_organizer = <AsyncMock id='4399174288'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106fde290>\nbackend = <AsyncMock spec='CrawlerBackend' id='4397147984'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4399173392'>\nmock_content_processor = <AsyncMock id='4411907152'>\nmock_quality_checker = <AsyncMock id='4412397968'>\nmock_document_organizer = <AsyncMock id='4412196112'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106fced50>\nbackend = <AsyncMock spec='CrawlerBackend' id='4399173392'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4397238160'>\nmock_content_processor = <AsyncMock id='4397081936'>\nmock_quality_checker = <AsyncMock id='4423404496'>\nmock_document_organizer = <AsyncMock id='4396864272'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106f1da50>\nbackend = <AsyncMock spec='CrawlerBackend' id='4397238160'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4398966032'>\nmock_content_processor = <AsyncMock id='4411562064'>\nmock_quality_checker = <AsyncMock id='4411568912'>\nmock_document_organizer = <AsyncMock id='4412257872'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106fbb250>\nbackend = <AsyncMock spec='CrawlerBackend' id='4398966032'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4423064592'>\nmock_content_processor = <AsyncMock id='4412392144'>\nmock_quality_checker = <AsyncMock id='4412205072'>\nmock_document_organizer = <AsyncMock id='4412197904'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106fa2ed0>\nbackend = <AsyncMock spec='CrawlerBackend' id='4423064592'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4397575568'>\nmock_content_processor = <AsyncMock id='4412198480'>\nmock_quality_checker = <AsyncMock id='4412386192'>\nmock_document_organizer = <AsyncMock id='4412035664'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x107a13090>\nbackend = <AsyncMock spec='CrawlerBackend' id='4397575568'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4412254224'>\nmock_content_processor = <AsyncMock id='4412251920'>\nmock_quality_checker = <AsyncMock id='4412121680'>\nmock_document_organizer = <AsyncMock id='4412115856'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x106f9d150>\nbackend = <AsyncMock spec='CrawlerBackend' id='4412254224'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 10}}, "6": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for CrawlResult\n       issues.0\n         Input should be a valid dictionary or instance of QualityIssue [type=model_type, input_value=\"1 validation error for C...c.dev/2.10/v/model_type\", input_type=str]\n           For further information visit https://errors.pydantic.dev/2.10/v/model_type\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "7": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'example' == 'uncategorized'\n     \n     - uncategorized\n     + example\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len({})\n    +    where {} = <src.organizers.doc_organizer.DocumentOrganizer object at 0x11086c910>.search_indices\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}}, "8": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: ContentProcessor._clean_text() got an unexpected keyword argument 'clean_regex'\n", "test_name": "test_clean_text_processing", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_code_language_detection", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_code_block_processing", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 'title' in {'text': 'link', 'type': 'internal', 'url': 'https://example.com'}\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'meta_tags' in {'description': 'Sample description', 'keywords': ['test', 'sample'], 'open_graph': {}, 'title': 'Sample Document', ...}\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_asset_collection", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n    +    where [] = <built-in method get of dict object at 0x106ffa740>('images', [])\n    +      where <built-in method get of dict object at 0x106ffa740> = {}.get\n    +        where {} = ProcessedContent(url='https://example.com/test', title='Sample Document', content={'title': 'Sample Document', 'formatted_content': '', 'headings': [{'level': 1, 'text': 'Main Title', 'id': ''}, {'level': 2, 'text': 'Section 1', 'id': ''}], 'links': [{'url': 'https://example.com', 'text': 'link', 'type': 'internal', 'source': 'content'}], 'code_blocks': [{'language': '', 'content': 'def hello():\\n                print(\"Hello, World!\")'}, {'language': 'language-python', 'content': 'def hello():\\n                print(\"Hello, World!\")'}], 'structure': []}, metadata={}, assets={}, errors=[]).assets\n", "test_name": "test_full_content_processing", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert not {'code_blocks': [], 'formatted_content': '', 'headings': [], 'links': [], ...}\n    +  where {'code_blocks': [], 'formatted_content': '', 'headings': [], 'links': [], ...} = ProcessedContent(url='https://example.com', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[]).content\n", "test_name": "test_content_size_limits", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "9": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_full_quality_check", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 9, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 0}}, "10": {"suite_name": "tests/test_url_handling.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert 'http://\u00fcnicode.com/' == 'http://xn--nicode-2ya.com/'\n         \n         - http://xn--nicode-2ya.com/\n         ?        ^^^^      ----\n         + http://\u00fcnicode.com/\n         ?        ^\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "FAIL", "message": "       assert True == False\n        +  where True = URLInfo(original=\"http://example.com/<script>alert('xss')</script>\", normalized=\"http://example.com/<script>alert('xss')</script>\", scheme='http', netloc='example.com', path=\"/<script>alert('xss')</script>\", is_valid=True).is_valid\n", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "FAIL", "message": "       TypeError: URLInfo.from_string() got an unexpected keyword argument 'base_url'\n", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_url_info_performance", "rerun": "0"}}, "status": {"total_pass": 12, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}}}, "date": "November 27, 2024", "start_time": 1732704065.742285, "total_suite": 11, "status": "FAIL", "status_list": {"pass": "55", "fail": "51", "skip": "0", "error": "10", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "116"}