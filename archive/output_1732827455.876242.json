{"content": {"suites": {"0": {"status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "FAIL", "message": "       TypeError: URLProcessor() takes no arguments\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 1 validation error for ProcessedContent\n   url\n     Field required [type=missing, input_value={'title': 'Test Document'...est', 'language': 'en'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'dict' object has no attribute 'total_requests'\n", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for BackendCriteria\n   priority\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   url_patterns\n     Field required [type=missing, input_value={'domains': ['example.com...t_types': ['text/html']}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_content_processor.py", "tests": {"0": {"status": "FAIL", "message": "   assert 1048576 == 1000000\n    +  where 1048576 = <src.processors.content_processor.ProcessingConfig object at 0x13e55f190>.max_content_length\n    +    where <src.processors.content_processor.ProcessingConfig object at 0x13e55f190> = <src.processors.content_processor.ContentProcessor object at 0x13e55f750>.config\n", "test_name": "test_init_default_config", "rerun": "0"}, "1": {"status": "FAIL", "message": "   TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_init_custom_config", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_extract_title_with_title_tag", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_extract_title_with_h1_fallback", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_extract_title_no_title", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_extract_text_basic", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_extract_text_with_scripts", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_extract_text_preserve_code", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_extract_headings", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_extract_links", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_extract_code_blocks", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_extract_images", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_extract_stylesheets", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_extract_scripts", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_extract_media", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AssertionError: assert 64 == 2\n    +  where 64 = len('Section 1\\nParagraph 1\\ndef test():\\n    pass\\nSection 2\\nParagraph 2')\n", "test_name": "test_extract_content_structure", "rerun": "0"}, "16": {"status": "PASS", "message": "", "test_name": "test_process_basic", "rerun": "0"}, "17": {"status": "PASS", "message": "", "test_name": "test_process_large_content", "rerun": "0"}, "18": {"status": "PASS", "message": "", "test_name": "test_find_main_content", "rerun": "0"}, "19": {"status": "FAIL", "message": "   AssertionError: assert 'Code block' in '# Heading 1\\nHeading 1\\nParagraph\\nParagraph\\nItem 1\\nItem 2\\n> Quote\\nQuote'\n", "test_name": "test_format_as_markdown", "rerun": "0"}, "20": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute '_convert_table_to_markdown'\n", "test_name": "test_convert_table_to_markdown", "rerun": "0"}, "21": {"status": "FAIL", "message": "   AssertionError: assert 'Test & content' in '<p>Test &amp; content</p>'\n", "test_name": "test_safe_content", "rerun": "0"}, "22": {"status": "FAIL", "message": "   TypeError: ContentProcessor._safe_content() got an unexpected keyword argument 'preserve_whitespace'\n", "test_name": "test_safe_content_preserve_whitespace", "rerun": "0"}, "23": {"status": "PASS", "message": "", "test_name": "test_safe_content_preserve_entities", "rerun": "0"}, "24": {"status": "FAIL", "message": "   KeyError: 'title'\n", "test_name": "test_extract_metadata", "rerun": "0"}, "25": {"status": "FAIL", "message": "   AssertionError: assert '/image.jpg' in ['https://example.com/image.jpg']\n", "test_name": "test_collect_assets", "rerun": "0"}, "26": {"status": "PASS", "message": "", "test_name": "test_extract_text_with_nested_content", "rerun": "0"}, "27": {"status": "FAIL", "message": "   AssertionError: assert 'Comment' not in 'Comment sho...ther comment'\n     \n     'Comment' is contained here:\n       Comment should be removed\n     ? +++++++\n       Visible text\n       Another comment\n", "test_name": "test_extract_text_with_comments", "rerun": "0"}, "28": {"status": "PASS", "message": "", "test_name": "test_extract_text_with_special_characters", "rerun": "0"}, "29": {"status": "PASS", "message": "", "test_name": "test_extract_headings_empty", "rerun": "0"}, "30": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_extract_headings_with_nested_content.<locals>.<genexpr> at 0x12fca82b0>)\n", "test_name": "test_extract_headings_with_nested_content", "rerun": "0"}, "31": {"status": "FAIL", "message": "   AssertionError: assert 3 == 0\n    +  where 3 = len([{'source': 'content', 'text': 'Email Link', 'type': 'internal', 'url': 'mailto:test@example.com'}, {'source': 'content', 'text': 'Hash Link', 'type': 'external', 'url': 'https://example.com'}, {'source': 'content', 'text': 'Whitespace Link', 'type': 'external', 'url': 'https://example.com'}])\n", "test_name": "test_extract_links_with_invalid_urls", "rerun": "0"}, "32": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_extract_links_with_relative_paths.<locals>.<genexpr> at 0x13e4f83c0>)\n", "test_name": "test_extract_links_with_relative_paths", "rerun": "0"}, "33": {"status": "FAIL", "message": "   assert 4 == 3\n    +  where 4 = len([{'content': 'def test():\\n    pass', 'language': 'language-python'}, {'content': \"console.log('test');\", 'language': 'javascript'}, {'content': \"puts 'test'\", 'language': ''}, {'content': \"puts 'test'\", 'language': 'ruby'}])\n", "test_name": "test_extract_code_blocks_with_attributes", "rerun": "0"}, "34": {"status": "FAIL", "message": "   AssertionError: assert 3 == 2\n    +  where 3 = len(['data:image/png;base64,abc123', '/image.jpg', ''])\n", "test_name": "test_extract_images_with_data_urls", "rerun": "0"}, "35": {"status": "PASS", "message": "", "test_name": "test_extract_stylesheets_with_media_queries", "rerun": "0"}, "36": {"status": "PASS", "message": "", "test_name": "test_extract_scripts_with_attributes", "rerun": "0"}, "37": {"status": "PASS", "message": "", "test_name": "test_extract_media_with_sources", "rerun": "0"}, "38": {"status": "PASS", "message": "", "test_name": "test_process_with_complex_metadata", "rerun": "0"}, "39": {"status": "FAIL", "message": "   assert 'script' not in '<img src=\"x.../evil.com\"/>'\n     \n     'script' is contained here:\n       <img src=\"x\"/>\n       <a href=\"javascript:alert('xss')\">click me</a>\n     ?              ++++++\n       <iframe src=\"evil.html\"></iframe>\n       <object></object>\n       <embed src=\"evil.swf\"/>\n       <base href=\"http://evil.com\"/>\n", "test_name": "test_safe_content_with_malicious_content", "rerun": "0"}, "40": {"status": "FAIL", "message": "   AssertionError: assert 'description' in {}\n", "test_name": "test_extract_metadata_with_missing_values", "rerun": "0"}, "41": {"status": "PASS", "message": "", "test_name": "test_collect_assets_with_base_tag", "rerun": "0"}, "42": {"status": "PASS", "message": "", "test_name": "test_process_with_invalid_html", "rerun": "0"}, "43": {"status": "PASS", "message": "", "test_name": "test_process_with_unicode_content", "rerun": "0"}, "44": {"status": "PASS", "message": "", "test_name": "test_process_with_mixed_content_types", "rerun": "0"}, "45": {"status": "PASS", "message": "", "test_name": "test_process_with_microdata", "rerun": "0"}, "46": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_process_with_frames.<locals>.<genexpr> at 0x13e1eb920>)\n", "test_name": "test_process_with_frames", "rerun": "0"}, "47": {"status": "PASS", "message": "", "test_name": "test_process_with_custom_elements", "rerun": "0"}, "48": {"status": "FAIL", "message": "   AssertionError: assert 'IE specific content' not in 'Conditional...ular content'\n     \n     'IE specific content' is contained here:\n       Conditional Comments\n       [if IE]>\n                   <p>IE specific content</p>\n                   <![endif]\n       [if !IE]><!...\n     \n     ...Full output truncated (6 lines hidden), use '-vv' to show\n", "test_name": "test_process_with_conditional_comments", "rerun": "0"}, "49": {"status": "PASS", "message": "", "test_name": "test_process_with_data_attributes", "rerun": "0"}, "50": {"status": "FAIL", "message": "   assert 'https://example.com/new' in \"{'title': 'Meta Redirect', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}\"\n    +  where \"{'title': 'Meta Redirect', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}\" = str({'author': '', 'custom': {}, 'date': '', 'description': '', ...})\n    +    where {'author': '', 'custom': {}, 'date': '', 'description': '', ...} = ProcessedContent(url='https://example.com', title='Meta Redirect', content={'title': 'Meta Redirect', 'formatted_content': 'Meta Redirect\\nRedirecting...\\nRedirecting...', 'headings': [], 'links': [], 'code_blocks': [], 'structure': 'Meta Redirect\\nRedirecting...'}, metadata={'title': 'Meta Redirect', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).metadata\n", "test_name": "test_process_with_meta_redirects", "rerun": "0"}, "51": {"status": "PASS", "message": "", "test_name": "test_process_with_base_urls", "rerun": "0"}, "52": {"status": "FAIL", "message": "   AssertionError: assert 'Nested content' in 'Nested paragraph 1\\nPreserved whitespace\\n                            and formatting\\ndef test():\\n    pass\\nNested\\ncontent'\n", "test_name": "test_extract_text_with_complex_content", "rerun": "0"}, "53": {"status": "PASS", "message": "", "test_name": "test_extract_text_with_sphinx_content", "rerun": "0"}, "54": {"status": "PASS", "message": "", "test_name": "test_extract_text_with_empty_elements", "rerun": "0"}, "55": {"status": "PASS", "message": "", "test_name": "test_extract_headings_with_ids", "rerun": "0"}, "56": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_extract_links_with_complex_navigation.<locals>.<genexpr> at 0x12e8eeea0>)\n", "test_name": "test_extract_links_with_complex_navigation", "rerun": "0"}, "57": {"status": "PASS", "message": "", "test_name": "test_extract_links_with_base_url", "rerun": "0"}, "58": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_extract_code_blocks_with_languages.<locals>.<genexpr> at 0x13e5b03c0>)\n", "test_name": "test_extract_code_blocks_with_languages", "rerun": "0"}, "59": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_extract_code_blocks_with_nested_content.<locals>.<genexpr> at 0x13e5b02e0>)\n", "test_name": "test_extract_code_blocks_with_nested_content", "rerun": "0"}, "60": {"status": "FAIL", "message": "   assert not True\n    +  where True = any(<generator object test_process_with_custom_config.<locals>.<genexpr> at 0x12e28d2f0>)\n", "test_name": "test_process_with_custom_config", "rerun": "0"}, "61": {"status": "FAIL", "message": "   NameError: name 'ProcessorConfig' is not defined\n", "test_name": "test_processor_with_size_limits", "rerun": "0"}, "62": {"status": "FAIL", "message": "   KeyError: 'custom_field'\n", "test_name": "test_processor_with_custom_extractors", "rerun": "0"}, "63": {"status": "FAIL", "message": "   AssertionError: assert 'Normal text with and .' in {'code_blocks': [], 'formatted_content': 'Normal text with SHOUTING and MORE SHOUTING.\\nNormal text with SHOUTING and MORE SHOUTING.\\nThis is OKAY to keep.\\nThis is OKAY to keep.', 'headings': [], 'links': [], ...}\n    +  where {'code_blocks': [], 'formatted_content': 'Normal text with SHOUTING and MORE SHOUTING.\\nNormal text with SHOUTING and MORE SHOUTING.\\nThis is OKAY to keep.\\nThis is OKAY to keep.', 'headings': [], 'links': [], ...} = ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': 'Normal text with SHOUTING and MORE SHOUTING.\\nNormal text with SHOUTING and MORE SHOUTING.\\nThis is OKAY to keep.\\nThis is OKAY to keep.', 'headings': [], 'links': [], 'code_blocks': [], 'structure': 'Normal text with SHOUTING and MORE SHOUTING.\\nThis is OKAY to keep.'}, metadata={'title': '', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_processor_with_custom_filters", "rerun": "0"}, "64": {"status": "FAIL", "message": "   KeyError: 'author'\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "65": {"status": "PASS", "message": "", "test_name": "test_asset_collection", "rerun": "0"}, "66": {"status": "FAIL", "message": "   AssertionError: assert '- First level 1' in 'First level 1\\nNested item 1\\nNested item 2\\nDeep nested item\\nFirst level 2\\nNumbered item 1\\nSub first\\nSub second\\nNumbered item 2\\nMixed content:\\nNumbered in unordered'\n", "test_name": "test_nested_list_formatting", "rerun": "0"}, "67": {"status": "FAIL", "message": "   AssertionError: assert '| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |' in {'code_blocks': [], 'formatted_content': '| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |\\nHeader 1\\nHeader 2\\nCell 1\\nCell 2\\nCell 3\\nCell 4', 'headings': [], 'links': [], ...}\n    +  where {'code_blocks': [], 'formatted_content': '| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |\\nHeader 1\\nHeader 2\\nCell 1\\nCell 2\\nCell 3\\nCell 4', 'headings': [], 'links': [], ...} = ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |\\nHeader 1\\nHeader 2\\nCell 1\\nCell 2\\nCell 3\\nCell 4', 'headings': [], 'links': [], 'code_blocks': [], 'structure': 'Header 1\\nHeader 2\\nCell 1\\nCell 2\\nCell 3\\nCell 4'}, metadata={'title': '', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_markdown_table_formatting", "rerun": "0"}, "68": {"status": "FAIL", "message": "   AssertionError: assert '- Level 1 Item 1\\n  - Level 2 Item 1\\n  - Level 2 Item 2\\n    - Level 3 Item 1\\n- Level 1 Item 2' in {'code_blocks': [], 'formatted_content': 'Level 1 Item 1\\nLevel 2 Item 1\\nLevel 2 Item 2\\nLevel 3 Item 1\\nLevel 1 Item 2', 'headings': [], 'links': [], ...}\n    +  where {'code_blocks': [], 'formatted_content': 'Level 1 Item 1\\nLevel 2 Item 1\\nLevel 2 Item 2\\nLevel 3 Item 1\\nLevel 1 Item 2', 'headings': [], 'links': [], ...} = ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': 'Level 1 Item 1\\nLevel 2 Item 1\\nLevel 2 Item 2\\nLevel 3 Item 1\\nLevel 1 Item 2', 'headings': [], 'links': [], 'code_blocks': [], 'structure': 'Level 1 Item 1\\nLevel 2 Item 1\\nLevel 2 Item 2\\nLevel 3 Item 1\\nLevel 1 Item 2'}, metadata={'title': '', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_nested_lists_formatting", "rerun": "0"}, "69": {"status": "FAIL", "message": "       assert '```python\\ndef hello():\\n    print(\"Hello, World!\")\\n```' in {'code_blocks': [{'content': 'def hello():\\n    print(\"Hello, World!\")', 'language': ''}, {'content': 'def hello():\\n    print(\"Hello, World!\")', 'language': 'language-python'}, {'content': 'print(\"Hi\")', 'language': ''}, {'content': '// No language specified\\nconsole.log(\"Hello\");', 'language': ''}, {'content': '// No language specified\\nconsole.log(\"Hello\");', 'language': ''}], 'formatted_content': '```python\\ndef hello():\\n    print(\"Hello, World!\")\\n```\\nInline code: print(\"Hi\")\\nInline code:\\n`print(\"Hi\")`\\n```\\n// No language specified\\nconsole.log(\"Hello\");\\n```', 'headings': [], 'links': [], ...}\n        +  where {'code_blocks': [{'content': 'def hello():\\n    print(\"Hello, World!\")', 'language': ''}, {'content': 'def hello():\\n    print(\"Hello, World!\")', 'language': 'language-python'}, {'content': 'print(\"Hi\")', 'language': ''}, {'content': '// No language specified\\nconsole.log(\"Hello\");', 'language': ''}, {'content': '// No language specified\\nconsole.log(\"Hello\");', 'language': ''}], 'formatted_content': '```python\\ndef hello():\\n    print(\"Hello, World!\")\\n```\\nInline code: print(\"Hi\")\\nInline code:\\n`print(\"Hi\")`\\n```\\n// No language specified\\nconsole.log(\"Hello\");\\n```', 'headings': [], 'links': [], ...} = ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '```python\\ndef hello():\\n    print(\"Hello, World!\")\\n```\\nInline code: print(\"Hi\")\\nInline code:\\n`print(\"Hi\")`\\n```\\n// No language specified\\nconsole.log(\"Hello\");\\n```', 'headings': [], 'links': [], 'code_blocks': [{'language': '', 'content': 'def hello():\\n    print(\"Hello, World!\")'}, {'language': 'language-python', 'content': 'def hello():\\n    print(\"Hello, World!\")'}, {'language': '', 'content': 'print(\"Hi\")'}, {'language': '', 'content': '// No language specified\\nconsole.log(\"Hello\");'}, {'language': '', 'content': '// No language specified\\nconsole.log(\"Hello\");'}], 'structure': 'def hello():\\n    print(\"Hello, World!\")\\nInline code:\\nprint(\"Hi\")\\n// No language specified\\nconsole.log(\"Hello\");'}, metadata={'title': '', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_code_blocks_formatting", "rerun": "0"}, "70": {"status": "FAIL", "message": "       assert '# Document Title' in {'code_blocks': [{'content': 'inline code', 'language': ''}, {'content': 'print(\"Hello\")', 'language': ''}, {'content': 'print(\"Hello\")', 'language': 'language-python'}], 'formatted_content': '# Document Title\\nDocument Title\\nIntroduction paragraph\\nIntroduction paragraph\\n| Name | Value |\\n| --- | --- |\\n| Item 1 | 100 |\\nName\\nValue\\nItem 1\\n100\\nList item with\\n`inline code`\\nList item with\\n[link](https://example.com)\\nlink\\n```python\\nprint(\"Hello\")\\n```', 'headings': [{'id': '', 'level': 1, 'text': 'Document Title'}], 'links': [{'source': 'content', 'text': 'link', 'type': 'external', 'url': 'https://example.com'}], ...}\n        +  where {'code_blocks': [{'content': 'inline code', 'language': ''}, {'content': 'print(\"Hello\")', 'language': ''}, {'content': 'print(\"Hello\")', 'language': 'language-python'}], 'formatted_content': '# Document Title\\nDocument Title\\nIntroduction paragraph\\nIntroduction paragraph\\n| Name | Value |\\n| --- | --- |\\n| Item 1 | 100 |\\nName\\nValue\\nItem 1\\n100\\nList item with\\n`inline code`\\nList item with\\n[link](https://example.com)\\nlink\\n```python\\nprint(\"Hello\")\\n```', 'headings': [{'id': '', 'level': 1, 'text': 'Document Title'}], 'links': [{'source': 'content', 'text': 'link', 'type': 'external', 'url': 'https://example.com'}], ...} = ProcessedContent(url='', title='Document Title', content={'title': 'Document Title', 'formatted_content': '# Document Title\\nDocument Title\\nIntroduction paragraph\\nIntroduction paragraph\\n| Name | Value |\\n| --- | --- |\\n| Item 1 | 100 |\\nName\\nValue\\nItem 1\\n100\\nList item with\\n`inline code`\\nList item with\\n[link](https://example.com)\\nlink\\n```python\\nprint(\"Hello\")\\n```', 'headings': [{'level': 1, 'text': 'Document Title', 'id': ''}], 'links': [{'url': 'https://example.com', 'text': 'link', 'type': 'external', 'source': 'content'}], 'code_blocks': [{'language': '', 'content': 'inline code'}, {'language': '', 'content': 'print(\"Hello\")'}, {'language': 'language-python', 'content': 'print(\"Hello\")'}], 'structure': 'Document Title\\nIntroduction paragraph\\nName\\nValue\\nItem 1\\n100\\nList item with\\ninline code\\nList item with\\nlink\\nprint(\"Hello\")'}, metadata={'title': 'Document Title', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_mixed_content_formatting", "rerun": "0"}, "71": {"status": "FAIL", "message": "   AttributeError: 'dict' object has no attribute 'strip'\n", "test_name": "test_empty_elements_handling", "rerun": "0"}, "72": {"status": "FAIL", "message": "   AssertionError: assert 'Unclosed cell' in {}\n    +  where {} = ProcessedContent(url='', title='Content Too Small', content={}, metadata={}, assets={}, errors=['Content size (97) below minimum (100)']).content\n", "test_name": "test_malformed_content_handling", "rerun": "0"}, "73": {"status": "FAIL", "message": "   AssertionError: assert 'More content' in '<p>Safe content</p>'\n", "test_name": "test_safe_content_with_scripts", "rerun": "0"}, "74": {"status": "PASS", "message": "", "test_name": "test_safe_content_with_entities", "rerun": "0"}, "75": {"status": "FAIL", "message": "   KeyError: 'title'\n", "test_name": "test_extract_metadata_complete", "rerun": "0"}, "76": {"status": "FAIL", "message": "   AssertionError: assert 'description' in {}\n", "test_name": "test_extract_metadata_auto_generation", "rerun": "0"}, "77": {"status": "PASS", "message": "", "test_name": "test_collect_assets_all_types", "rerun": "0"}, "78": {"status": "FAIL", "message": "   AssertionError: assert False\n    +  where False = isinstance('Main Title\\nIntroduction text\\nSection 1\\nSection 1 content\\ndef test():\\n                    pass\\nSection 2\\nSection 2 content\\nImportant quote\\nSubsection\\nSubsection content', list)\n", "test_name": "test_extract_content_structure_complex", "rerun": "0"}, "79": {"status": "FAIL", "message": "   AssertionError: assert '- Item 1' in '# Title\\nTitle\\nParagraph 1\\nParagraph 1\\nItem 1\\nItem 2\\nNumber 1\\nNumber 2\\n> Important quote\\nImportant quote\\n```python\\ndef test():\\n    pass\\n```'\n", "test_name": "test_format_as_markdown_mixed_content", "rerun": "0"}, "80": {"status": "PASS", "message": "", "test_name": "test_format_as_markdown_nested_content", "rerun": "0"}, "81": {"status": "PASS", "message": "", "test_name": "test_find_main_content_with_article", "rerun": "0"}, "82": {"status": "PASS", "message": "", "test_name": "test_find_main_content_with_sphinx", "rerun": "0"}, "83": {"status": "FAIL", "message": "   assert 'Test content with\\n           preserved whitespace' in {'code_blocks': [], 'formatted_content': \"Test content with preserved whitespace\\nTest content with\\n           preserved whitespace\\nalert('test');\\nStyled text\", 'headings': [], 'links': [], ...}\n    +  where {'code_blocks': [], 'formatted_content': \"Test content with preserved whitespace\\nTest content with\\n           preserved whitespace\\nalert('test');\\nStyled text\", 'headings': [], 'links': [], ...} = ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': \"Test content with preserved whitespace\\nTest content with\\n           preserved whitespace\\nalert('test');\\nStyled text\", 'headings': [], 'links': [], 'code_blocks': [], 'structure': \"Test content with\\n           preserved whitespace\\nalert('test');\\nStyled text\"}, metadata={'title': '', 'description': '', 'keywords': [], 'author': '', 'date': '', 'language': '', 'meta_tags': {}, 'opengraph': {}, 'twitter': {}, 'schema': {}, 'dublin_core': {}, 'custom': {}}, assets={'images': [], 'stylesheets': [], 'scripts': [], 'media': []}, errors=[]).content\n", "test_name": "test_processor_configuration", "rerun": "0"}, "84": {"status": "FAIL", "message": "   AssertionError: assert 'Custom content' in {}\n    +  where {} = ProcessedContent(url='', title='Content Too Small', content={}, metadata={}, assets={}, errors=['Content size (104) below minimum (100)']).content\n", "test_name": "test_processor_with_custom_transformers", "rerun": "0"}, "85": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_processor_error_handling.<locals>.<genexpr> at 0x13e5b0580>)\n", "test_name": "test_processor_error_handling", "rerun": "0"}, "86": {"status": "FAIL", "message": "   KeyError: 'icons'\n", "test_name": "test_processor_asset_handling", "rerun": "0"}, "87": {"status": "FAIL", "message": "   KeyError: 'embeds'\n", "test_name": "test_processor_with_embedded_content", "rerun": "0"}, "88": {"status": "FAIL", "message": "   assert '- First level' in '# Main Title\\nMain Title\\nThis is a paragraph with bold and italic text.\\nThis is a paragraph with\\nbold\\nand\\nitalic\\ntext.\\n## Nested Lists\\nNested Lists\\nFirst level\\nSecond level\\nOrdered sub-item 1\\nOrdered sub-item 2\\nAnother second level\\nAnother first level\\n## Code Blocks\\nCode Blocks\\n```python\\ndef example():\\n    return \"Hello World\"\\n```\\nInline code example\\nInline\\n`code`\\nexample\\n## Tables\\nTables\\n| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |\\nHeader 1\\nHeader 2\\nCell 1\\nCell 2\\nCell 3\\nCell 4\\n## Links and Images\\nLinks and Images\\nHere\\'s a link and an image:\\nHere\\'s a\\n[link](https://example.com)\\nlink\\nand an image:\\n![Example Image](//image.jpg)\\n## Blockquotes\\nBlockquotes\\n> This is a blockquote with multiple paragraphs.Second paragraph in blockquote.\\nThis is a blockquote with multiple paragraphs.\\nThis is a blockquote with multiple paragraphs.\\nSecond paragraph in blockquote.\\nSecond paragraph in blockquote.\\n## Mixed Content\\nMixed Content\\nParagraph before list\\nParagraph before list\\nList item with\\nbold\\nList item with\\n`code`\\nParagraph after list\\nParagraph after list'\n", "test_name": "test_format_as_markdown_comprehensive", "rerun": "0"}, "89": {"status": "FAIL", "message": "   NameError: name 're' is not defined\n", "test_name": "test_format_as_markdown_edge_cases", "rerun": "0"}}, "status": {"total_pass": 42, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 48, "total_error": 0}}, "2": {"suite_name": "tests/test_content_processor_advanced.py", "tests": {"0": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_basic_html_processing", "rerun": "0"}, "1": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_code_block_extraction", "rerun": "0"}, "2": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_table_processing", "rerun": "0"}, "3": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_list_processing", "rerun": "0"}, "4": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_image_processing", "rerun": "0"}, "6": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_heading_hierarchy", "rerun": "0"}, "7": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_special_characters", "rerun": "0"}, "8": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_content_cleanup", "rerun": "0"}, "9": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_performance", "rerun": "0"}, "10": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_error_handling", "rerun": "0"}, "11": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_content_processor_advanced.py:8: TypeError\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "12": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor_normalization", "rerun": "0"}, "13": {"status": "FAIL", "message": "               AttributeError: 'URLInfo' object has no attribute 'url_type'\n", "test_name": "test_url_type_detection", "rerun": "0"}, "14": {"status": "FAIL", "message": "   assert False\n    +  where False = URLInfo(raw_url='http://example.com', normalized_url='http://example.com', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_validation", "rerun": "0"}, "15": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 2 validation errors for URLInfo\n       raw_url\n         Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n           For further information visit https://errors.pydantic.dev/2.10/v/string_type\n       normalized_url\n         Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n           For further information visit https://errors.pydantic.dev/2.10/v/string_type\n", "test_name": "test_url_processor_edge_cases", "rerun": "0"}, "16": {"status": "PASS", "message": "", "test_name": "test_url_processor_security", "rerun": "0"}, "17": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://m\u00fcnchen.de', normalized_url='http://m\u00fcnchen.de', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_international", "rerun": "0"}, "18": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='./page', normalized_url='./page', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_relative_paths", "rerun": "0"}, "19": {"status": "FAIL", "message": "               AttributeError: 'URLInfo' object has no attribute 'url_type'\n", "test_name": "test_url_processor_asset_types", "rerun": "0"}, "20": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com/?a=1&b=2', normalized_url='http://example.com/?a=1&b=2', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_query_handling", "rerun": "0"}, "21": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com', normalized_url='http://example.com', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_scheme_handling", "rerun": "0"}, "22": {"status": "FAIL", "message": "           assert False\n            +  where False = URLInfo(raw_url='http://example.com:80', normalized_url='http://example.com:80', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_port_handling", "rerun": "0"}, "23": {"status": "FAIL", "message": "           assert 'authentication' in \"url normalization failed: name 'idna' is not defined\"\n            +  where \"url normalization failed: name 'idna' is not defined\" = <built-in method lower of str object at 0x13e749ae0>()\n            +    where <built-in method lower of str object at 0x13e749ae0> = \"URL normalization failed: name 'idna' is not defined\".lower\n            +      where \"URL normalization failed: name 'idna' is not defined\" = URLInfo(raw_url='http://user:pass@example.com', normalized_url='http://user:pass@example.com', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").error_msg\n", "test_name": "test_url_processor_auth_handling", "rerun": "0"}, "24": {"status": "FAIL", "message": "           assert False\n            +  where False = any(<generator object test_url_processor_ip_handling.<locals>.<genexpr> at 0x13e4fa5e0>)\n", "test_name": "test_url_processor_ip_handling", "rerun": "0"}, "25": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com/caf\u00e9', normalized_url='http://example.com/caf\u00e9', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_unicode_normalization", "rerun": "0"}, "26": {"status": "FAIL", "message": "           assert 'domain' in \"url normalization failed: name 'idna' is not defined\"\n            +  where \"url normalization failed: name 'idna' is not defined\" = <built-in method lower of str object at 0x13e748810>()\n            +    where <built-in method lower of str object at 0x13e748810> = \"URL normalization failed: name 'idna' is not defined\".lower\n            +      where \"URL normalization failed: name 'idna' is not defined\" = URLInfo(raw_url='http://example', normalized_url='http://example', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").error_msg\n", "test_name": "test_url_processor_domain_validation", "rerun": "0"}, "27": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com/normal/path', normalized_url='http://example.com/normal/path', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_path_validation", "rerun": "0"}, "28": {"status": "FAIL", "message": "       assert False == True\n        +  where False = URLInfo(raw_url='http://example.com?normal=value', normalized_url='http://example.com?normal=value', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_query_validation", "rerun": "0"}, "29": {"status": "FAIL", "message": "       assert False\n        +  where False = URLInfo(raw_url='http://example.com#section', normalized_url='http://example.com#section', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_fragment_handling", "rerun": "0"}, "30": {"status": "FAIL", "message": "   NameError: name 'RateLimiter' is not defined\n", "test_name": "test_rate_limiter", "rerun": "0"}, "31": {"status": "FAIL", "message": "   NameError: name 'RetryStrategy' is not defined\n", "test_name": "test_retry_strategy", "rerun": "0"}, "32": {"status": "FAIL", "message": "   NameError: name 'calculate_similarity' is not defined\n", "test_name": "test_calculate_similarity", "rerun": "0"}, "33": {"status": "FAIL", "message": "   NameError: name 'generate_checksum' is not defined\n", "test_name": "test_generate_checksum", "rerun": "0"}, "34": {"status": "PASS", "message": "", "test_name": "test_timer", "rerun": "0"}, "35": {"status": "FAIL", "message": "   NameError: name 'setup_logging' is not defined\n", "test_name": "test_setup_logging", "rerun": "0"}, "36": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor_normalize_url", "rerun": "0"}, "37": {"status": "FAIL", "message": "   AssertionError: assert <URLType.EXTERNAL: 'external'> == <URLType.INTERNAL: 'internal'>\n    +  where <URLType.EXTERNAL: 'external'> = <bound method URLProcessor._determine_url_type of <class 'src.utils.helpers.URLProcessor'>>('/page', 'http://example.com')\n    +    where <bound method URLProcessor._determine_url_type of <class 'src.utils.helpers.URLProcessor'>> = <src.utils.helpers.URLProcessor object at 0x13e7e3890>._determine_url_type\n    +  and   <URLType.INTERNAL: 'internal'> = URLType.INTERNAL\n", "test_name": "test_url_processor_determine_type", "rerun": "0"}, "38": {"status": "FAIL", "message": "   NameError: name 'RateLimiter' is not defined\n", "test_name": "test_rate_limiter_wait", "rerun": "0"}, "39": {"status": "FAIL", "message": "   assert False\n    +  where False = URLInfo(raw_url='http://example.com/page', normalized_url='http://example.com/page', scheme='unknown', netloc='', path='', is_valid=False, error_msg=\"URL normalization failed: name 'idna' is not defined\").is_valid\n", "test_name": "test_url_processor_process_url", "rerun": "0"}, "40": {"status": "FAIL", "message": "       NameError: name 'time' is not defined\n", "test_name": "test_timer_duration", "rerun": "0"}}, "status": {"total_pass": 2, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 27, "total_error": 12}}, "3": {"suite_name": "tests/test_content_processor_edge.py", "tests": {"0": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'src.processors.content_processor.ContentProcessingError'>\n", "test_name": "test_empty_content", "rerun": "0"}, "1": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_malformed_html", "rerun": "0"}, "2": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_special_characters", "rerun": "0"}, "3": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_large_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_nested_structures", "rerun": "0"}, "5": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_javascript_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_style_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_iframe_handling", "rerun": "0"}, "8": {"status": "FAIL", "message": "               AttributeError: 'ProcessedContent' object has no attribute 'processed_content'\n", "test_name": "test_form_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "4": {"suite_name": "tests/test_crawl4ai.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_basic", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawl_with_rate_limit", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_validate_content", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('content' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'} or 'error' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'})\n", "test_name": "test_process_content", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_backend_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metrics", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 == 500\n    +  where 0 = CrawlResult(url='https://invalid-url-that-does-not-exist.com', content={}, metadata={}, status=0, error='Failed after 2 retries: Cannot connect to host invalid-url-that-does-not-exist.com:443 ssl:default [nodename nor servname provided, or not known]', timestamp=datetime.datetime(2024, 11, 28, 20, 51, 42, 664246)).status\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_concurrent_requests", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_crawl4ai_config_validation", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_ssl_context_configuration", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_custom_headers_handling", "rerun": "0"}, "12": {"status": "FAIL", "message": "   assert 200 == 403\n    +  where 200 = CrawlResult(url='https://other-domain.com/page', content={'html': '<!DOCTYPE html>\\n<html lang=\"ja\">\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, viewport-fit=cover\">\\n\\t<title>\u4f9d\u983c\u5148\u306e\u9078\u3073\u65b9\u3084\u5370\u5237\u65b9\u6cd5\u306a\u3069\uff01\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f\u306b\u7b54\u3048\u307e\u3059\uff01\uff5c\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f\\u30002024\u5e7411\u6708\u66f4\u65b0</title>\\n\\t<meta name=\"description\" content=\"\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u3092\u59cb\u3081\u3066\u884c\u3046\u3068\u306a\u3063\u305f\u3068\u304d\u3001\u591a\u304f\u306e\u4eba\u3005\u306f\u4f55\u304b\u3089\u624b\u3092\u4ed8\u3051\u308b\u3079\u304d\u304b\u8ff7\u3046\u306e\u3067\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u304b\u3002\u3002\">\\n\\t<link href=\"https://fonts.googleapis.com/css?family=Sawarabi+Gothic\" rel=\"stylesheet\">\\n\\t<link rel=\"stylesheet\" href=\"css/app.css\">\\n</head>\\n<body>\\n<div id=\"site\">\\n<div id=\"header\" class=\"navbar\"><div class=\"container-fluid\">\\n\\t<a href=\"./\" class=\"navbar-brand\">\\n\\t\\t<img width=\"200px\" height=\"40px\" src=\"./img/logo.png\" alt=\"\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f\">\\n\\t</a>\\n\\t<button class=\"navbar-toggler collapsed\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#navigation\" aria-controls=\"navigation\" aria-expanded=\"false\">\\n\\t\\t<span class=\"navbar-toggler-icon\"></span>\\n\\t\\t<span class=\"navbar-toggler-icon\"></span>\\n\\t\\t<span class=\"navbar-toggler-icon\"></span>\\n\\t</button>\\n</div></div>\\n<div id=\"navigation\" class=\"collapse navbar-collapse\"><div class=\"container-fluid\">\\n\\t<ul cla...024.08.22\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u6700\u65b0\u30c8\u30ec\u30f3\u30c9\u3068\u74b0\u5883\u3078\u306e\u914d\u616e\\n2024.3.15\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u3092\u5909\u9769\u3059\u308b\u30c7\u30b8\u30bf\u30eb\u306e\u529b\uff1a\u512a\u4f4d\u6027\u3068\u53ef\u80fd\u6027\u306b\u8feb\u308b\\n2024.3.15\\n\u6280\u8853\u9769\u65b0\u304c\u3082\u305f\u3089\u3059\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u9032\u5316\u3068\u30c7\u30b6\u30a4\u30f3\u306e\u5909\u9769\\n2024.3.15\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u304c\u98df\u54c1\u5b89\u5168\u6027\u306b\u4e0e\u3048\u308b\u5f71\u97ff\u3068\u305d\u306e\u91cd\u8981\u6027\u306b\u3064\u3044\u3066\u306e\u8003\u5bdf\\n2024.3.15\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u30c7\u30b6\u30a4\u30f3\u306e\u30ab\u30e9\u30fc\u30b5\u30a4\u30a8\u30f3\u30b9\\n2024.3.15\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u65b9\u6cd5\uff5c\u30db\u30c3\u30c8\u30b9\u30bf\u30f3\u30d7\u306e\u7279\u5fb4\u306f\uff1f\\n2023.10.16\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u898b\u7a4d\u3082\u308a\u6642\u306b\u6ce8\u610f\u3059\u3079\u304d\u30dd\u30a4\u30f3\u30c8\u306f\uff1f\\n2023.10.16\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u652f\u6255\u3044\u65b9\u6cd5\u306b\u306f\u3069\u306e\u3088\u3046\u306a\u7a2e\u985e\u304c\u3042\u308b\uff1f\\n2023.10.16\\n\u904e\u53bb\u306b\u5236\u4f5c\u3057\u305f\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u73fe\u7269\u304b\u3089\u540c\u3058\u30c7\u30b6\u30a4\u30f3\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306f\u53ef\u80fd\uff1f\\n2023.10.16\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u3067\u3088\u304f\u3042\u308b\u5931\u6557\u306f\uff1f\\n2023.10.16\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306f\u3069\u306e\u3088\u3046\u306a\u7d20\u6750\u3067\u3082\u53ef\u80fd\uff1f\\n2023.05.24\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u65b9\u6cd5\uff5c\u30aa\u30d5\u30bb\u30c3\u30c8\u5370\u5237\u306e\u7279\u5fb4\\n2023.05.24\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u65b9\u6cd5\uff5c\u30b0\u30e9\u30d3\u30a2\u5370\u5237\u306e\u7279\u5fb4\\n2023.05.24\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u65b9\u6cd5\uff5c\u30d5\u30ec\u30ad\u30bd\u5370\u5237\u306e\u7279\u5fb4\\n2023.05.24\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u65b9\u6cd5\uff5c\u30b7\u30eb\u30af\u5370\u5237\u306e\u7279\u5fb4\\n2023.05.24\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u4f9d\u983c\u5148\u3092\u9078\u3076\u969b\u306e\u30dd\u30a4\u30f3\u30c8\u306f\uff1f\\n2023.04.25\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u3092\u4f9d\u983c\u3059\u308b\u969b\u306e\u6d41\u308c\u306f\uff1f\\n2023.04.25\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306e\u7d0d\u671f\u306f\u3069\u308c\u304f\u3089\u3044\u304c\u76ee\u5b89\uff1f\\n2023.04.25\\n\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306f1\u679a\u304b\u3089\u306e\u5c0f\u30ed\u30c3\u30c8\u3067\u3082\u767a\u6ce8\u3067\u304d\u308b\uff1f\\n2023.04.25\\n\u00a9 2024 \u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f', 'links': [], 'title': '\u4f9d\u983c\u5148\u306e\u9078\u3073\u65b9\u3084\u5370\u5237\u65b9\u6cd5\u306a\u3069\uff01\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f\u306b\u7b54\u3048\u307e\u3059\uff01\uff5c\u30d1\u30c3\u30b1\u30fc\u30b8\u5370\u5237\u306b\u95a2\u3059\u308b\u3088\u304f\u3042\u308b\u7591\u554f\\u30002024\u5e7411\u6708\u66f4\u65b0'}, metadata={'headers': {'Date': 'Thu, 28 Nov 2024 20:51:56 GMT', 'Server': 'Apache/2.4.62 (Unix) OpenSSL/1.1.1k', 'X-Powered-By': 'PHP/7.4.33', 'Vary': 'Accept-Encoding,User-Agent', 'Content-Encoding': 'gzip', 'Content-Length': '15014', 'Content-Type': 'text/html; charset=UTF-8'}}, status=200, error=None, timestamp=datetime.datetime(2024, 11, 28, 20, 51, 42, 664246)).status\n", "test_name": "test_domain_filtering", "rerun": "0"}, "13": {"status": "FAIL", "message": "   assert 5 == 3\n    +  where 5 = len([CrawlResult(url='https://example.com/page0', content={'html': '<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature...      margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n', 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'links': [], 'title': 'Example Domain'}, metadata={'headers': {'Content-Encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Age': '488259', 'Cache-Control': 'max-age=604800', 'Content-Type': 'text/html', 'Date': 'Thu, 28 Nov 2024 20:52:01 GMT', 'Etag': '\"1088432560+gzip\"', 'Expires': 'Thu, 05 Dec 2024 20:52:01 GMT', 'Last-Modified': 'Sat, 12 Oct 2024 03:26:51 GMT', 'Server': 'ECAcc (dcd/7D44)', 'Vary': 'Accept-Encoding', 'X-Cache': '404-HIT', 'Content-Length': '648'}}, status=404, error=None, timestamp=datetime.datetime(2024, 11, 28, 20, 51, 42, 664246))])\n", "test_name": "test_url_queue_management", "rerun": "0"}}, "status": {"total_pass": 8, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "5": {"suite_name": "tests/test_crawl4ai_extended.py", "tests": {"0": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 6 validation errors for URLInfo\n   raw_url\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   normalized_url\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   scheme\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   netloc\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   path\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   is_valid\n     Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_crawl_with_urlinfo", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'requests'\n", "test_name": "test_crawl_depth_first", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert False\n    +  where False = all(<generator object test_rate_limiting_precision.<locals>.<genexpr> at 0x13e6d0380>)\n", "test_name": "test_rate_limiting_precision", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_concurrent_request_limit", "rerun": "0"}, "4": {"status": "FAIL", "message": "           pydantic_core._pydantic_core.ValidationError: 6 validation errors for URLInfo\n           raw_url\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n           normalized_url\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n           scheme\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n           netloc\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n           path\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n           is_valid\n             Field required [type=missing, input_value={'url': 'https://example.com'}, input_type=dict]\n               For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "           assert 0 == 500\n            +  where 0 = CrawlResult(url='https://nonexistent.example.com', content={}, metadata={}, status=0, error=\"Failed after 2 retries: 'coroutine' object does not support the asynchronous context manager protocol\", timestamp=datetime.datetime(2024, 11, 28, 20, 51, 42, 664246)).status\n", "test_name": "test_error_propagation", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'get'\n", "test_name": "test_retry_behavior", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_metrics_accuracy", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'closed'\n", "test_name": "test_resource_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   TypeError: BaseModel.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "10": {"status": "FAIL", "message": "   TypeError: BaseModel.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "11": {"status": "FAIL", "message": "   TypeError: BaseModel.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}, "12": {"status": "FAIL", "message": "   TypeError: BaseModel.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_url_info_hashable", "rerun": "0"}, "13": {"status": "FAIL", "message": "   TypeError: BaseModel.__init__() takes 1 positional argument but 2 were given\n", "test_name": "test_url_info_immutable", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 13, "total_error": 0}}, "6": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_statistics_tracking", "rerun": "0"}, "11": {"status": "FAIL", "message": "   NameError: name 'ProjectType' is not defined\n", "test_name": "test_project_type_enum", "rerun": "0"}, "12": {"status": "FAIL", "message": "   NameError: name 'ProjectIdentity' is not defined\n", "test_name": "test_project_identity", "rerun": "0"}, "13": {"status": "FAIL", "message": "   NameError: name 'ProjectIdentifier' is not defined\n", "test_name": "test_project_identifier", "rerun": "0"}, "14": {"status": "FAIL", "message": "   NameError: name 'DUCKDUCKGO_AVAILABLE' is not defined\n", "test_name": "test_duckduckgo_search", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute '_discover_urls'\n", "test_name": "test_url_discovery", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'ProjectIdentifier' object has no attribute '_identify_project_type'\n", "test_name": "test_project_type_detection", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 11}}, "7": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5343710928'>\nmock_content_processor = <AsyncMock id='5344742544'>\nmock_quality_checker = <AsyncMock id='5344598800'>\nmock_document_organizer = <AsyncMock id='5341550352'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e931050>\nbackend = <AsyncMock spec='CrawlerBackend' id='5343710928'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5344888848'>\nmock_content_processor = <AsyncMock id='5344893520'>\nmock_quality_checker = <AsyncMock id='5345237648'>\nmock_document_organizer = <AsyncMock id='5344630160'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e90ae90>\nbackend = <AsyncMock spec='CrawlerBackend' id='5344888848'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5343709968'>\nmock_content_processor = <AsyncMock id='5344803472'>\nmock_quality_checker = <AsyncMock id='5343805840'>\nmock_document_organizer = <AsyncMock id='5344944464'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e9d6b90>\nbackend = <AsyncMock spec='CrawlerBackend' id='5343709968'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5345118096'>\nmock_content_processor = <AsyncMock id='5345127952'>\nmock_quality_checker = <AsyncMock id='5345418000'>\nmock_document_organizer = <AsyncMock id='5344768720'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e9732d0>\nbackend = <AsyncMock spec='CrawlerBackend' id='5345118096'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5343958736'>\nmock_content_processor = <AsyncMock id='5344936400'>\nmock_quality_checker = <AsyncMock id='5344763344'>\nmock_document_organizer = <AsyncMock id='5344776208'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e902810>\nbackend = <AsyncMock spec='CrawlerBackend' id='5343958736'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5345349008'>\nmock_content_processor = <AsyncMock id='5345359376'>\nmock_quality_checker = <AsyncMock id='5345485648'>\nmock_document_organizer = <AsyncMock id='5345194832'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e91a610>\nbackend = <AsyncMock spec='CrawlerBackend' id='5345349008'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5343712720'>\nmock_content_processor = <AsyncMock id='5344356368'>\nmock_quality_checker = <AsyncMock id='5344595600'>\nmock_document_organizer = <AsyncMock id='5344973392'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e926710>\nbackend = <AsyncMock spec='CrawlerBackend' id='5343712720'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5345607632'>\nmock_content_processor = <AsyncMock id='5345389008'>\nmock_quality_checker = <AsyncMock id='5345168400'>\nmock_document_organizer = <AsyncMock id='5344816016'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e93f6d0>\nbackend = <AsyncMock spec='CrawlerBackend' id='5345607632'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5345054032'>\nmock_content_processor = <AsyncMock id='5344801296'>\nmock_quality_checker = <AsyncMock id='5344592144'>\nmock_document_organizer = <AsyncMock id='5344842128'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e925850>\nbackend = <AsyncMock spec='CrawlerBackend' id='5345054032'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='5362515152'>\nmock_content_processor = <AsyncMock id='5362609488'>\nmock_quality_checker = <AsyncMock id='5345302416'>\nmock_document_organizer = <AsyncMock id='5362625232'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x13e9eaf10>\nbackend = <AsyncMock spec='CrawlerBackend' id='5362515152'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 10}}, "8": {"suite_name": "tests/test_document_processor.py", "tests": {"0": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_basic_document_processing", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_empty_document", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_no_title", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_multiple_titles", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_complex_content", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_invalid_url", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_frames", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_scripts", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_meta_redirects", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_base_tag", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_special_content", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_lists", "rerun": "0"}, "12": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_tables", "rerun": "0"}, "13": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_forms", "rerun": "0"}, "14": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_semantic_elements", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_media_elements", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_interactive_elements", "rerun": "0"}, "17": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_embedded_content", "rerun": "0"}, "18": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_ruby_annotations", "rerun": "0"}, "19": {"status": "FAIL", "message": "   AttributeError: 'DocumentProcessor' object has no attribute 'process_document'\n", "test_name": "test_document_with_math_content", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 20, "total_error": 0}}, "9": {"suite_name": "tests/test_gui.py", "tests": {"0": {"status": "FAIL", "message": "       jinja2.exceptions.TemplateNotFound: index.html\n", "test_name": "test_home_page", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'error' == 'success'\n     \n     - success\n     + error\n", "test_name": "test_crawl_request", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_connection_manager", "rerun": "0"}, "3": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for ProcessedContent\n   title\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   content\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_crawler_thread", "rerun": "0"}, "4": {"status": "FAIL", "message": "   NameError: name 'ResultsViewer' is not defined\n", "test_name": "test_results_viewer", "rerun": "0"}, "5": {"status": "FAIL", "message": "   pydantic_core._pydantic_core.ValidationError: 2 validation errors for ProcessedContent\n   title\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n   content\n     Field required [type=missing, input_value={'url': 'https://example....type': 'documentation'}}, input_type=dict]\n       For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_save_results", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: Expected 'critical' to have been called once. Called 0 times.\n       AssertionError: Expected 'critical' to have been called once. Called 0 times.\n", "test_name": "test_error_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "10": {"suite_name": "tests/test_helpers.py", "tests": {"0": {"status": "FAIL", "message": "           NameError: name 'idna' is not defined\n       ValueError: URL normalization failed: name 'idna' is not defined\n", "test_name": "test_url_processor", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'RateLimiter' object has no attribute 'delay'\n", "test_name": "test_rate_limiter", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: RetryStrategy.__init__() got an unexpected keyword argument 'base_delay'\n", "test_name": "test_retry_strategy", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'Timer' object has no attribute 'elapsed'\n", "test_name": "test_timer", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 0.7777777777777778 > 0.8\n    +  where 0.7777777777777778 = calculate_similarity('This is a test document about Python programming', 'This is a test document about Python coding')\n", "test_name": "test_similarity_calculation", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_checksum_generation", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: assert None == <MagicMock name='getLogger()' id='5345558992'>\n", "test_name": "test_logging_setup", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "11": {"suite_name": "tests/test_html_processor.py", "tests": {"0": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_basic_html_processing", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_empty_html", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_malformed_html", "rerun": "0"}, "3": {"status": "FAIL", "message": "       AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_html_encoding", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_html_entities", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_doctype_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_comment_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_script_handling", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_style_handling", "rerun": "0"}, "9": {"status": "FAIL", "message": "           AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_meta_charset_handling", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_iframe_handling", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_form_handling", "rerun": "0"}, "12": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_svg_handling", "rerun": "0"}, "13": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_math_ml_handling", "rerun": "0"}, "14": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_custom_elements", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_data_attributes", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_conditional_comments", "rerun": "0"}, "17": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_template_handling", "rerun": "0"}, "18": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_picture_source_handling", "rerun": "0"}, "19": {"status": "FAIL", "message": "   AttributeError: 'HTMLProcessor' object has no attribute 'process_html'\n", "test_name": "test_unicode_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 20, "total_error": 0}}, "12": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_full_site_crawl0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_content_processing_pipeli0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_quality_checks0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_document_organization0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_search_functionality0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "ERROR", "message": "test_html_dir = '/private/var/folders/c6/0glsj2qj54s2pr7y8ncq92l40000gn/T/pytest-of-alex/pytest-130/test_error_handling_and_recove0/test_docs'\n\n    @pytest.fixture\n    def integrated_crawler(test_html_dir: str) -> DocumentationCrawler:\n        \"\"\"Create fully integrated crawler instance.\"\"\"\n        # Configure backend\n        backend = Crawl4AIBackend(\n            config=Crawl4AIConfig(\n                max_retries=2,\n                timeout=5.0,\n                headers={\"User-Agent\": \"TestCrawler/1.0\"}\n            )\n        )\n    \n        # Configure backend selector\n        selector = BackendSelector()\n        selector.register_backend(\n            backend,\n            BackendCriteria(\n                priority=100,\n                content_types=[\"text/html\"],\n                url_patterns=[\"*\"],\n                max_load=0.8,\n                min_success_rate=0.7\n            )\n        )\n    \n        # Configure content processor\n        processor = ContentProcessor(\n>           config=ProcessingConfig(\n                allowed_tags=[\n                    \"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"code\",\n                    \"a\", \"ul\", \"li\", \"nav\"\n                ],\n                preserve_whitespace_elements=[\"pre\", \"code\"],\n                code_languages=[\"python\"],\n                max_heading_level=3,\n                max_content_length=10000,\n                min_content_length=10\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n\ntests/test_integration.py:135: TypeError\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 6}}, "13": {"suite_name": "tests/test_integration_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_full_crawl_pipeline", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute 'backend'\n", "test_name": "test_error_handling_integration", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: Crawl4AIBackend.__init__() got an unexpected keyword argument 'rate_limiter'\n", "test_name": "test_rate_limiting_integration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'DocumentationCrawler' object has no attribute 'backend'\n", "test_name": "test_content_processing_integration", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}, "14": {"suite_name": "tests/test_link_processor.py", "tests": {"0": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_basic_link_extraction", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_empty_document", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_malformed_links", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_duplicate_links", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_fragment_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_query_params", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_special_characters", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_nested_links", "rerun": "0"}, "8": {"status": "FAIL", "message": "       AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_invalid_base_url", "rerun": "0"}, "9": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_data_urls", "rerun": "0"}, "10": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_unicode_urls", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_protocol_relative_urls", "rerun": "0"}, "12": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_base_tag_handling", "rerun": "0"}, "13": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_malformed_base_tags", "rerun": "0"}, "14": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_link_attributes", "rerun": "0"}, "15": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_link_schemes", "rerun": "0"}, "16": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_url_normalization", "rerun": "0"}, "17": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_url_case_sensitivity", "rerun": "0"}, "18": {"status": "FAIL", "message": "   AttributeError: 'LinkProcessor' object has no attribute 'extract_links'\n", "test_name": "test_url_encoding_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 19, "total_error": 0}}, "15": {"suite_name": "tests/test_metadata_extraction.py", "tests": {"0": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_basic_metadata_extraction", "rerun": "0"}, "1": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_metadata_fallbacks", "rerun": "0"}, "2": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_empty_metadata", "rerun": "0"}, "3": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_mixed_meta_properties", "rerun": "0"}, "4": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_duplicate_meta_tags", "rerun": "0"}, "5": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_keyword_generation", "rerun": "0"}, "6": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_special_characters_metadata", "rerun": "0"}, "7": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_long_content_truncation", "rerun": "0"}, "8": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_malformed_meta_tags", "rerun": "0"}, "9": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_html_entities_in_meta", "rerun": "0"}, "10": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_nested_content_keyword_generation", "rerun": "0"}, "11": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_multilingual_content", "rerun": "0"}, "12": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_schema_org_metadata", "rerun": "0"}, "13": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_meta_robots_handling", "rerun": "0"}, "14": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_json_ld_fallback", "rerun": "0"}, "15": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_relative_urls_in_meta", "rerun": "0"}, "16": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_whitespace_handling", "rerun": "0"}, "17": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_unicode_metadata", "rerun": "0"}, "18": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_nested_html_metadata", "rerun": "0"}, "19": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_mixed_case_metadata", "rerun": "0"}, "20": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_duplicate_keywords_handling", "rerun": "0"}, "21": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_special_punctuation_handling", "rerun": "0"}, "22": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_schema_metadata_priority", "rerun": "0"}, "23": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_keyword_relevance", "rerun": "0"}, "24": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_empty_content_handling", "rerun": "0"}, "25": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_safe_content_edge_cases", "rerun": "0"}, "26": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_invalid_meta_tags", "rerun": "0"}, "27": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_malformed_opengraph", "rerun": "0"}, "28": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_xss_prevention", "rerun": "0"}, "29": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_extreme_content_lengths", "rerun": "0"}, "30": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_mixed_metadata_formats", "rerun": "0"}, "31": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_special_meta_tags", "rerun": "0"}, "32": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_metadata_inheritance", "rerun": "0"}, "33": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_language_metadata", "rerun": "0"}, "34": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_empty_document", "rerun": "0"}, "35": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_malformed_html_structure", "rerun": "0"}, "36": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_nested_meta_tags", "rerun": "0"}, "37": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_encoded_content", "rerun": "0"}, "38": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_json_ld_metadata", "rerun": "0"}, "39": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_rdfa_metadata", "rerun": "0"}, "40": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_microdata_metadata", "rerun": "0"}, "41": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_meta_refresh_handling", "rerun": "0"}, "42": {"status": "ERROR", "message": "@pytest.fixture\n    def processor():\n>       return ContentProcessor(ProcessingConfig())\nE       TypeError: ContentProcessor.__init__() takes 1 positional argument but 2 were given\n\ntests/test_metadata_extraction.py:7: TypeError\n", "test_name": "test_invalid_charset_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 43}}, "16": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = DocumentMetadata(title='Test Document', url='https://example.com/doc', category='reference', tags=['test', 'version', 'document'], versions=[], references={'internal': [], 'external': [], 'code': []}, index_terms=['test', 'document'], last_updated=datetime.datetime(2024, 11, 28, 22, 54, 3, 904220)).versions\n", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'example' is None\n    +  where 'example' = DocumentMetadata(title='Miscellaneous', url='https://example.com/misc', category='example', tags=['content', 'miscellaneous', 'random'], versions=[], references={'internal': [], 'external': [], 'code': []}, index_terms=['miscellaneous'], last_updated=datetime.datetime(2024, 11, 28, 22, 54, 3, 915424)).category\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_search_index_generation.<locals>.<genexpr> at 0x13fd299a0>)\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 4, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "17": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "FAIL", "message": "   TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'preserve_whitespace_elements'\n", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_clean_text_processing", "rerun": "0"}, "2": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_code_language_detection", "rerun": "0"}, "3": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_code_block_processing", "rerun": "0"}, "4": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_metadata_extraction", "rerun": "0"}, "6": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_asset_collection", "rerun": "0"}, "7": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_full_content_processing", "rerun": "0"}, "8": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_content_size_limits", "rerun": "0"}, "9": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_malformed_html_handling", "rerun": "0"}, "10": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_special_content_handling", "rerun": "0"}, "11": {"status": "ERROR", "message": "@pytest.fixture\n    def content_processor() -> ContentProcessor:\n        \"\"\"Configured content processor.\"\"\"\n        return ContentProcessor(\n>           config=ProcessingConfig(\n                extract_headings=True,\n                extract_code=True,\n                extract_links=True,\n                min_content_length=10,\n                max_content_length=10000\n            )\n        )\nE       TypeError: ProcessingConfig.__init__() got an unexpected keyword argument 'extract_headings'\n\ntests/conftest.py:177: TypeError\n", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 1, "total_error": 11}}, "18": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_content_length_check.<locals>.<genexpr> at 0x13e979ff0>)\n", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_heading_structure_check.<locals>.<genexpr> at 0x13e83d540>)\n", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_link_validation.<locals>.<genexpr> at 0x13fd2a340>)\n", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_metadata_check.<locals>.<genexpr> at 0x13fd28f20>)\n", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "FAIL", "message": "   assert False\n    +  where False = any(<generator object test_code_block_validation.<locals>.<genexpr> at 0x13fd299a0>)\n", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_quality_issue_initialization", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_quality_issue_location_handling", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_issue_metadata", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_full_quality_check", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "19": {"suite_name": "tests/test_url_handling.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "FAIL", "message": "       AssertionError: assert 'https://example.com/path' == 'https://example.com/path/'\n         \n         - https://example.com/path/\n         ?                         -\n         + https://example.com/path\n", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: assert not True\n        +  where True = URLInfo(raw_url='not a url', normalized_url='http://not a url/', scheme='http', netloc='not a url', path='/', is_valid=True, error_msg='').is_valid\n", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'Exception'>\n", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert 'http://\u00fcnicode.com/' == 'http://xn--nicode-2ya.com/'\n         \n         - http://xn--nicode-2ya.com/\n         ?        ^^^^      ----\n         + http://\u00fcnicode.com/\n         ?        ^\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "FAIL", "message": "       assert True == False\n        +  where True = URLInfo(raw_url=\"http://example.com/page?id=1' OR '1'='1\", normalized_url=\"http://example.com/page?id=1' OR '1'='1\", scheme='http', netloc='example.com', path='/page', is_valid=True, error_msg='').is_valid\n", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_url_info_performance", "rerun": "0"}}, "status": {"total_pass": 10, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}}}, "date": "November 28, 2024", "start_time": 1732827245.31395, "total_suite": 20, "status": "FAIL", "status_list": {"pass": "79", "fail": "206", "skip": "0", "error": "93", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "378"}