{"content": {"suites": {"0": {"status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 1, "total_error": 0}, "tests": {"0": {"status": "FAIL", "message": "       AssertionError: assert 'https://exam...age1/../page2' == 'https://example.com/page2'\n         \n         - https://example.com/page2\n         + https://example.com/page1/../page2\n         ?                         +++++++++\n", "test_name": "test_url_normalization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}}, "suite_name": "tests/test_crawl4ai_extended.py"}, "1": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "FAIL", "message": "           AssertionError: Expected documents for http://example.com/./path/../page, but got none.\n           assert []\n            +  where [] = CrawlResult(target=CrawlTarget(url='http://example.com/./path/../page', depth=1, follow_external=False, content_types=..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).documents\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 1, "total_error": 0}}}}, "date": "April 11, 2025", "start_time": 1744376840.1768134, "total_suite": 2, "status": "FAIL", "status_list": {"pass": "3", "fail": "2", "skip": "0", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "5"}