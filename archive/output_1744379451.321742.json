{"content": {"suites": {"0": {"status": {"total_pass": 4, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 11, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AssertionError: assert 'https://example.com' == 'https://example.com/'\n         \n         - https://example.com/\n         ?                    -\n         + https://example.com\n", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "FAIL", "message": "       AssertionError: assert 'https://exam..././to/../page' == 'https://exam...com/path/page'\n         \n         - https://example.com/path/page\n         + https://example.com/path/./to/../page\n         ?                          ++++++++\n", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "FAIL", "message": "       AssertionError: assert 'example.com' == 'http://example.com/'\n         \n         - http://example.com/\n         + example.com\n", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       AssertionError: assert 'https://exam...ery=1&param=2' == 'https://exam...ery=1&param=2'\n         \n         - https://example.com/?query=1&param=2\n         ?                    -\n         + https://example.com?query=1&param=2\n", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "       AssertionError: assert 'https://exam...path#fragment' == 'https://example.com/path'\n         \n         - https://example.com/path\n         + https://example.com/path#fragment\n         ?                         +++++++++\n", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "FAIL", "message": "       AssertionError: assert None == ''\n        +  where None = <src.utils.url_info.URLInfo object at 0x7fcadb048f50>.netloc\n", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "FAIL", "message": "   assert False\n    +  where False = isinstance(None, str)\n    +    where None = <src.utils.url_info.URLInfo object at 0x7fcadb04b290>.netloc\n", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert 'http://\u00fcnicode.com' == 'http://xn--nicode-2ya.com/'\n         \n         - http://xn--nicode-2ya.com/\n         ?        ^^^^      ----    -\n         + http://\u00fcnicode.com\n         ?        ^\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "FAIL", "message": "       AssertionError: assert 'page2.html' == 'http://examp...cs/page2.html'\n         \n         - http://example.com/docs/page2.html\n         + page2.html\n", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "FAIL", "message": "       AssertionError: assert 'http://examp...param1=value1' == 'http://examp...param1=value1'\n         \n         - http://example.com/?param1=value1\n         ?                   -\n         + http://example.com?param1=value1\n", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "FAIL", "message": "       assert False\n        +  where False = <src.utils.url_info.URLInfo object at 0x7fcadaf3d880>.is_valid\n", "test_name": "test_url_info_performance", "rerun": "0"}}, "suite_name": "tests/test_url_handling.py"}, "1": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "FAIL", "message": "       AssertionError: assert 0 == 1\n        +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 798395), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.001303, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n        +    where CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 798395), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.001303, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='http://example.com', depth=1, follow_external=False, content_types=['text/html'], ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).stats\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 816349), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.000378, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).failed_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 816349), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.000378, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='http://nonexistent.com', depth=1, follow_external=False, content_types=['text/html..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).stats\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 828915), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.000359, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).successful_crawls\n    +    where CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 28, 828915), end_time=datetime.datetime(2025, 4, 11, 13, ...cessful_crawls=0, failed_crawls=0, total_time=0.000359, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='http://example.com', depth=1, follow_external=False, content_types=['text/html'], ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).stats\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "SKIP", "message": "('/home/alex/DEV/lib2docScrape/tests/test_crawler_advanced.py', 157, 'Skipped: Rate limiter timing is difficult to test reliably with mocks')\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "FAIL", "message": "       AssertionError: Expected 'process' to have been called once. Called 0 times.\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='http://example.com', depth=1, follow_external=False, content_types=['text/html'], ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).issues\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 == 5\n    +  where 0 = sum(<generator object test_crawler_concurrent_requests.<locals>.<genexpr> at 0x7fcadb1a1540>)\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "FAIL", "message": "           AssertionError: Expected documents for http://EXAMPLE.com, but got none.\n           assert []\n            +  where [] = CrawlResult(target=CrawlTarget(url='http://EXAMPLE.com', depth=1, follow_external=False, content_types=['text/html'], ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).documents\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "FAIL", "message": "       AssertionError: assert 0 == 1\n        +  where 0 = len([])\n        +    where [] = CrawlResult(target=CrawlTarget(url='http://example.com', depth=1, follow_external=False, content_types=['text/html'], ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).issues\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 1, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "2": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: Expected pages crawled > 0, got 0\n   assert 0 > 0\n    +  where 0 = CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 29, 6334), end_time=datetime.datetime(2025, 4, 11, 13, 50...cessful_crawls=0, failed_crawls=0, total_time=0.000401, average_time_per_page=0.0, quality_issues=0, bytes_processed=0).pages_crawled\n    +    where CrawlStats(start_time=datetime.datetime(2025, 4, 11, 13, 50, 29, 6334), end_time=datetime.datetime(2025, 4, 11, 13, 50...cessful_crawls=0, failed_crawls=0, total_time=0.000401, average_time_per_page=0.0, quality_issues=0, bytes_processed=0) = CrawlResult(target=CrawlTarget(url='file:///tmp/pytest-of-alex/pytest-37/test_full_site_crawl0/test_docs/index.html', ..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).stats\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: Expected 1 document for guide.html, got 0\n   assert 0 == 1\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file:///tmp/pytest-of-alex/pytest-37/test_content_processing_pipeli0/test_docs/gui..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).documents\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: Metrics for file:///tmp/pytest-of-alex/pytest-37/test_quality_checks0/test_docs/api.html not found\n   assert 'file:///tmp/pytest-of-alex/pytest-37/test_quality_checks0/test_docs/api.html' in {}\n    +  where {} = CrawlResult(target=CrawlTarget(url='file:///tmp/pytest-of-alex/pytest-37/test_quality_checks0/test_docs/api.html', dep..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).metrics\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: Should have crawled all 4 pages\n   assert 0 == 4\n    +  where 0 = len([])\n    +    where [] = CrawlResult(target=CrawlTarget(url='file:///tmp/pytest-of-alex/pytest-37/test_document_organization0/test_docs/index.h..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).documents\n", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: Organizer should have 4 documents\n   assert 0 == 4\n    +  where 0 = len({})\n    +    where {} = <src.organizers.doc_organizer.DocumentOrganizer object at 0x7fcadad6c140>.documents\n    +      where <src.organizers.doc_organizer.DocumentOrganizer object at 0x7fcadad6c140> = <src.crawler.DocumentationCrawler object at 0x7fcadad6c290>.document_organizer\n", "test_name": "test_search_functionality", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 5, "total_error": 0}}, "3": {"suite_name": "tests/test_integration_advanced.py", "tests": {"0": {"status": "FAIL", "message": "           AssertionError: assert 0 > 0\n            +  where 0 = len([])\n            +    where [] = CrawlResult(target=CrawlTarget(url='https://example.com', depth=2, follow_external=False, content_types=['text/html'],..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).documents\n", "test_name": "test_full_crawl_pipeline", "rerun": "0"}, "1": {"status": "FAIL", "message": "       AssertionError: assert 0 == 1\n        +  where 0 = len([])\n        +    where [] = CrawlResult(target=CrawlTarget(url='https://example.com', depth=1, follow_external=False, content_types=['text/html'],..., documents=[], issues=[], metrics={}, structure=None, processed_url=None, failed_urls=[], errors={}, crawled_pages={}).failed_urls\n", "test_name": "test_error_handling_integration", "rerun": "0"}, "2": {"status": "FAIL", "message": "       AssertionError: Expected some delay due to rate limiting, but got 0.0030s\n       assert 0.003000000026077032 > 0.4\n", "test_name": "test_rate_limiting_integration", "rerun": "0"}, "3": {"status": "FAIL", "message": "       KeyError: 'https://example.com'\n", "test_name": "test_content_processing_integration", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 4, "total_error": 0}}, "4": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'Mock Title' == 'Sample Document'\n     \n     - Sample Document\n     + Mock Title\n", "test_name": "test_full_content_processing", "rerun": "0"}, "2": {"status": "FAIL", "message": "           AttributeError: Mock object has no attribute 'config'\n", "test_name": "test_content_size_limits", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "5": {"status": "FAIL", "message": "   assert 0 == 2\n    +  where 0 = len([])\n", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 3, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}, "5": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_basic", "rerun": "0"}, "1": {"status": "FAIL", "message": "   assert not True\n    +  where True = any(<generator object test_quality_checker_content_length.<locals>.<genexpr> at 0x7fcadad1b780>)\n", "test_name": "test_quality_checker_content_length", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_quality_checker_headings", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_quality_checker_links", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_quality_checker_code_blocks", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_quality_checker_metadata", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 1 == 0\n    +  where 1 = len([QualityIssue(type=<IssueType.CONTENT_LENGTH: 'content_length'>, level=<IssueLevel.ERROR: 'error'>, message='Content length (0) is below minimum (50)', location=None, details={})])\n", "test_name": "test_quality_checker_custom_config", "rerun": "0"}}, "status": {"total_pass": 5, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}}}}, "date": "April 11, 2025", "start_time": 1744379430.044387, "total_suite": 6, "status": "FAIL", "status_list": {"pass": "13", "fail": "33", "skip": "1", "error": "0", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "47"}