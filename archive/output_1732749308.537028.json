{"content": {"suites": {"0": {"status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}, "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_lifecycle", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawler_backend_error_handling", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_backend_selector_registration", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert 'crawl4ai' == 'MockCrawlerBackend'\n     \n     - MockCrawlerBackend\n     + crawl4ai\n", "test_name": "test_backend_selector_selection", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_processed_content_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_concurrent_backend_operations", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_backend_metrics_update", "rerun": "0"}, "8": {"status": "FAIL", "message": "   Failed: DID NOT RAISE <class 'ValueError'>\n", "test_name": "test_backend_selector_error_handling", "rerun": "0"}}, "suite_name": "tests/test_base.py"}, "1": {"suite_name": "tests/test_content_processor_advanced.py", "tests": {"0": {"status": "FAIL", "message": "   AssertionError: assert 'Main Title' in ProcessedContent(url='', title='Test Page', content={'title': 'Test Page', 'formatted_content': '', 'headings': [{'level': 1, 'text': 'Main Title', 'id': ''}], 'links': [], 'code_blocks': [{'language': '', 'content': 'def test(): pass'}], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_basic_html_processing", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert 'def example():' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [], 'code_blocks': [{'language': '', 'content': 'def example():\\n    return True'}, {'language': 'python', 'content': 'def example():\\n    return True'}, {'language': '', 'content': 'function test() {\\n    return true;\\n}'}, {'language': 'javascript', 'content': 'function test() {\\n    return true;\\n}'}], 'structure': [{'type': 'text', 'content': 'def example():\\n    return Truefunction test() {\\n    return true;\\n}'}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_code_block_extraction", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AssertionError: assert 'Header 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '| Header 1 | Header 2 |\\n| --- | --- |\\n| Cell 1 | Cell 2 |\\n| Cell 3 | Cell 4 |\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_table_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('* Item 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '- Item 1\\n- Item 2\\n\\n\\n1. First\\n2. Second\\n\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[]) or '- Item 1' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '- Item 1\\n- Item 2\\n\\n\\n1. First\\n2. Second\\n\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[]))\n", "test_name": "test_list_processing", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AssertionError: assert 'Example Link' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [{'url': 'https://example.com', 'text': 'Example Link', 'type': 'external', 'source': 'content'}, {'url': 'relative/path', 'text': 'Relative Link', 'type': 'internal', 'source': 'content'}], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AssertionError: assert 'Test Image' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [], 'code_blocks': [], 'structure': []}, metadata={}, assets={}, errors=[])\n", "test_name": "test_image_processing", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert '# Main Title' in ProcessedContent(url='', title='Main Title', content={'title': 'Main Title', 'formatted_content': '\\n# Main Title\\n\\n\\n## Subtitle\\n\\n\\n### Section\\n\\n\\n#### Subsection\\n', 'headings': [{'level': 1, 'text': 'Main Title', 'id': ''}, {'level': 2, 'text': 'Subtitle', 'id': ''}, {'level': 3, 'text': 'Section', 'id': ''}, {'level': 4, 'text': 'Subsection', 'id': ''}], 'links': [], 'code_blocks': [], 'structure': [{'type': 'section', 'level': 1, 'title': 'Main Title', 'content': []}, {'type': 'section', 'level': 2, 'title': 'Subtitle', 'content': []}, {'type': 'section', 'level': 3, 'title': 'Section', 'content': []}, {'type': 'section', 'level': 4, 'title': 'Subsection', 'content': []}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_heading_hierarchy", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AssertionError: assert ('\u00a9' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '\u00a9 2024\\n\\n<example>\\n\\n\u20ac symbol\\n\\n\u6f22\u5b57\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': [{'type': 'text', 'content': '\u00a9 2024'}, {'type': 'text', 'content': '<example>'}, {'type': 'text', 'content': '\u20ac symbol'}, {'type': 'text', 'content': '\u6f22\u5b57'}]}, metadata={}, assets={}, errors=[]) or '(c)' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '\u00a9 2024\\n\\n<example>\\n\\n\u20ac symbol\\n\\n\u6f22\u5b57\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': [{'type': 'text', 'content': '\u00a9 2024'}, {'type': 'text', 'content': '<example>'}, {'type': 'text', 'content': '\u20ac symbol'}, {'type': 'text', 'content': '\u6f22\u5b57'}]}, metadata={}, assets={}, errors=[]))\n", "test_name": "test_special_characters", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Valid content' in ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': '', 'headings': [], 'links': [], 'code_blocks': [], 'structure': [{'type': 'text', 'content': 'Valid content'}]}, metadata={}, assets={}, errors=[])\n", "test_name": "test_content_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "   TypeError: object of type 'ProcessedContent' has no len()\n", "test_name": "test_performance", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert False\n        +  where False = isinstance(ProcessedContent(url='', title='Untitled Document', content={'title': 'Untitled Document', 'formatted_content': 'Unclosed paragraph\\n', 'headings': [], 'links': [], 'code_blocks': [], 'structure': [{'type': 'text', 'content': 'Unclosed paragraph'}]}, metadata={}, assets={}, errors=[]), str)\n", "test_name": "test_error_handling", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AttributeError: 'ContentProcessor' object has no attribute 'extract_metadata'\n", "test_name": "test_metadata_extraction", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 12, "total_error": 0}}, "2": {"suite_name": "tests/test_crawl4ai.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawl_basic", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_crawl_with_rate_limit", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_validate_content", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AssertionError: assert ('content' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'} or 'error' in {'links': [], 'text': 'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...', 'title': 'Example Domain'})\n", "test_name": "test_process_content", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_backend_selection", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metrics", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AssertionError: assert 0 == 500\n    +  where 0 = CrawlResult(url='https://invalid-url-that-does-not-exist.com', content={}, metadata={}, status=0, error='Failed after 2 retries: Cannot connect to host invalid-url-that-does-not-exist.com:443 ssl:default [nodename nor servname provided, or not known]').status\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_concurrent_requests", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_cleanup", "rerun": "0"}}, "status": {"total_pass": 7, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}}, "3": {"suite_name": "tests/test_crawl4ai_extended.py", "tests": {"0": {"status": "FAIL", "message": "   assert 0 == 200\n    +  where 0 = CrawlResult(url='https://example.com/', content={}, metadata={}, status=0, error=\"Failed after 2 retries: 'coroutine' object does not support the asynchronous context manager protocol\").status\n", "test_name": "test_crawl_with_urlinfo", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'requests'\n", "test_name": "test_crawl_depth_first", "rerun": "0"}, "2": {"status": "FAIL", "message": "   assert False\n    +  where False = all(<generator object test_rate_limiting_precision.<locals>.<genexpr> at 0x11309bc60>)\n", "test_name": "test_rate_limiting_precision", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_concurrent_request_limit", "rerun": "0"}, "4": {"status": "FAIL", "message": "           AssertionError: assert 'https://example.com/' == 'https://example.com'\n             \n             - https://example.com\n             + https://example.com/\n             ?                    +\n", "test_name": "test_url_normalization", "rerun": "0"}, "5": {"status": "FAIL", "message": "           assert 0 == 500\n            +  where 0 = CrawlResult(url='https://nonexistent.example.com', content={}, metadata={}, status=0, error=\"Failed after 2 retries: 'coroutine' object does not support the asynchronous context manager protocol\").status\n", "test_name": "test_error_propagation", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'get'\n", "test_name": "test_retry_behavior", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert None is not None\n", "test_name": "test_metrics_accuracy", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'NoneType' object has no attribute 'closed'\n", "test_name": "test_resource_cleanup", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org/3/-expected0]", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_url_info_initialization[https://docs.python.org-expected1]", "rerun": "0"}, "11": {"status": "FAIL", "message": "   AssertionError: assert 'http://invalid-url' == 'invalid-url'\n     \n     - invalid-url\n     + http://invalid-url\n     ? +++++++\n", "test_name": "test_url_info_initialization[invalid-url-expected2]", "rerun": "0"}, "12": {"status": "PASS", "message": "", "test_name": "test_url_info_hashable", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_url_info_immutable", "rerun": "0"}}, "status": {"total_pass": 5, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 9, "total_error": 0}}, "4": {"suite_name": "tests/test_crawler.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_crawler_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AssertionError: assert not True\n    +  where True = _should_crawl_url('https://example.com/excluded/page', CrawlTarget(url='https://example.com/doc1', depth=2, follow_external=False, content_types=['text/html'], exclude_patterns=['/excluded/'], required_patterns=['/doc'], max_pages=10, allowed_paths=[], excluded_paths=[]))\n    +    where _should_crawl_url = <src.crawler.DocumentationCrawler object at 0x11328ae10>._should_crawl_url\n", "test_name": "test_url_filtering", "rerun": "0"}, "2": {"status": "FAIL", "message": "   TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_single_url_processing", "rerun": "0"}, "3": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_depth_limited_crawling", "rerun": "0"}, "4": {"status": "FAIL", "message": "       TypeError: DocumentationCrawler._process_url() takes 4 positional arguments but 5 were given\n", "test_name": "test_concurrent_processing", "rerun": "0"}, "5": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_rate_limiting", "rerun": "0"}, "6": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_error_handling", "rerun": "0"}, "7": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "8": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_cleanup", "rerun": "0"}, "9": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_max_pages_limit", "rerun": "0"}, "10": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ol\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_statistics_tracking", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 10, "total_error": 0}}, "5": {"suite_name": "tests/test_crawler_advanced.py", "tests": {"0": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4613857808'>\nmock_content_processor = <AsyncMock id='4616590544'>\nmock_quality_checker = <AsyncMock id='4614048528'>\nmock_document_organizer = <AsyncMock id='4614050192'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1132b1f10>\nbackend = <AsyncMock spec='CrawlerBackend' id='4613857808'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_basic_crawl", "rerun": "0"}, "1": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4597325456'>\nmock_content_processor = <AsyncMock id='4616831056'>\nmock_quality_checker = <AsyncMock id='4616841744'>\nmock_document_organizer = <AsyncMock id='4597248528'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1120e89d0>\nbackend = <AsyncMock spec='CrawlerBackend' id='4597325456'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_failed_crawl", "rerun": "0"}, "2": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4614212944'>\nmock_content_processor = <AsyncMock id='4640448336'>\nmock_quality_checker = <AsyncMock id='4583907152'>\nmock_document_organizer = <AsyncMock id='4640500496'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1132ee450>\nbackend = <AsyncMock spec='CrawlerBackend' id='4614212944'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_retry_mechanism", "rerun": "0"}, "3": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4616718864'>\nmock_content_processor = <AsyncMock id='4616296848'>\nmock_quality_checker = <AsyncMock id='4640492880'>\nmock_document_organizer = <AsyncMock id='4613795152'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1149a8250>\nbackend = <AsyncMock spec='CrawlerBackend' id='4616718864'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_rate_limiting", "rerun": "0"}, "4": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4598941648'>\nmock_content_processor = <AsyncMock id='4614061072'>\nmock_quality_checker = <AsyncMock id='4615996880'>\nmock_document_organizer = <AsyncMock id='4583910416'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x11493cc50>\nbackend = <AsyncMock spec='CrawlerBackend' id='4598941648'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_content_processing", "rerun": "0"}, "5": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4615995920'>\nmock_content_processor = <AsyncMock id='4640565456'>\nmock_quality_checker = <AsyncMock id='4616305040'>\nmock_document_organizer = <AsyncMock id='4640491088'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x114956010>\nbackend = <AsyncMock spec='CrawlerBackend' id='4615995920'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_quality_checking", "rerun": "0"}, "6": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4597239248'>\nmock_content_processor = <AsyncMock id='4597237392'>\nmock_quality_checker = <AsyncMock id='4597328272'>\nmock_document_organizer = <AsyncMock id='4597912336'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x1132f6550>\nbackend = <AsyncMock spec='CrawlerBackend' id='4597239248'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_resource_cleanup", "rerun": "0"}, "7": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4598770192'>\nmock_content_processor = <AsyncMock id='4613993488'>\nmock_quality_checker = <AsyncMock id='4614381584'>\nmock_document_organizer = <AsyncMock id='4640556240'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x11308ff10>\nbackend = <AsyncMock spec='CrawlerBackend' id='4598770192'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_concurrent_requests", "rerun": "0"}, "8": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4614561680'>\nmock_content_processor = <AsyncMock id='4597154320'>\nmock_quality_checker = <AsyncMock id='4597154192'>\nmock_document_organizer = <AsyncMock id='4640704912'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x114967550>\nbackend = <AsyncMock spec='CrawlerBackend' id='4614561680'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_url_normalization", "rerun": "0"}, "9": {"status": "ERROR", "message": "mock_backend = <AsyncMock spec='CrawlerBackend' id='4616587536'>\nmock_content_processor = <AsyncMock id='4616559952'>\nmock_quality_checker = <AsyncMock id='4598852432'>\nmock_document_organizer = <AsyncMock id='4613867408'>\n\n    @pytest.fixture\n    def crawler(mock_backend, mock_content_processor, mock_quality_checker, mock_document_organizer):\n        crawler = DocumentationCrawler(\n            content_processor=mock_content_processor,\n            quality_checker=mock_quality_checker,\n            document_organizer=mock_document_organizer\n        )\n>       crawler.backend_selector.register_backend(mock_backend, None)\n\ntests/test_crawler_advanced.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.backends.selector.BackendSelector object at 0x11496c1d0>\nbackend = <AsyncMock spec='CrawlerBackend' id='4616587536'>, criteria = None\n\n    def register_backend(\n        self,\n        backend: CrawlerBackend,\n        criteria: BackendCriteria\n    ) -> None:\n        \"\"\"\n        Register a crawler backend with selection criteria.\n    \n        Args:\n            backend: The crawler backend instance\n            criteria: Selection criteria for the backend\n    \n        Raises:\n            ValueError: If backend name is not set or if criteria is invalid\n        \"\"\"\n        if not hasattr(backend, 'name') or not backend.name:\n>           raise ValueError(\"Backend must have a name\")\nE           ValueError: Backend must have a name\n\nsrc/backends/selector.py:87: ValueError\n", "test_name": "test_crawler_error_handling", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 10}}, "6": {"suite_name": "tests/test_integration.py", "tests": {"0": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_full_site_crawl", "rerun": "0"}, "1": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_content_processing_pipeline", "rerun": "0"}, "2": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_quality_checks", "rerun": "0"}, "3": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_document_organization", "rerun": "0"}, "4": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "       pydantic_core._pydantic_core.ValidationError: 1 validation error for QualityIssue\n       rule_name\n         Field required [type=missing, input_value={'type': 'error', 'messag...ng\", 'severity': 'high'}, input_type=dict]\n           For further information visit https://errors.pydantic.dev/2.10/v/missing\n", "test_name": "test_error_handling_and_recovery", "rerun": "0"}}, "status": {"total_pass": 0, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 6, "total_error": 0}}, "7": {"suite_name": "tests/test_organizer.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_document_organizer_initialization", "rerun": "0"}, "1": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_document_version_management", "rerun": "0"}, "2": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_document_categorization", "rerun": "0"}, "3": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_reference_extraction", "rerun": "0"}, "4": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_search_functionality", "rerun": "0"}, "5": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_collection_management", "rerun": "0"}, "6": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_document_similarity", "rerun": "0"}, "7": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_version_tracking", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AttributeError: 'DocumentOrganizer' object has no attribute '_update_search_indices'\n", "test_name": "test_search_index_generation", "rerun": "0"}}, "status": {"total_pass": 1, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 8, "total_error": 0}}, "8": {"suite_name": "tests/test_processor.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_content_processor_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_clean_text_processing", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_code_language_detection", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_code_block_processing", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_link_processing", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_metadata_extraction", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_asset_collection", "rerun": "0"}, "7": {"status": "FAIL", "message": "   assert 0 > 0\n    +  where 0 = len([])\n    +    where [] = <built-in method get of dict object at 0x1149a8540>('images', [])\n    +      where <built-in method get of dict object at 0x1149a8540> = {}.get\n    +        where {} = ProcessedContent(url='https://example.com/test', title='Sample Document', content={'title': 'Sample Document', 'formatted_content': '', 'headings': [{'level': 1, 'text': 'Main Title', 'id': ''}, {'level': 2, 'text': 'Section 1', 'id': ''}], 'links': [{'url': 'https://example.com', 'text': 'link', 'type': 'internal', 'source': 'content'}], 'code_blocks': [{'language': '', 'content': 'def hello():\\n                print(\"Hello, World!\")'}, {'language': 'language-python', 'content': 'def hello():\\n                print(\"Hello, World!\")'}], 'structure': []}, metadata={}, assets={}, errors=[]).assets\n", "test_name": "test_full_content_processing", "rerun": "0"}, "8": {"status": "FAIL", "message": "   AssertionError: assert 'Content exceeds maximum size limit' in ['Content size (10034) exceeds limit (10000)']\n    +  where ['Content size (10034) exceeds limit (10000)'] = ProcessedContent(url='https://example.com', title='Content Too Large', content={}, metadata={}, assets={}, errors=['Content size (10034) exceeds limit (10000)']).errors\n", "test_name": "test_content_size_limits", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_malformed_html_handling", "rerun": "0"}, "10": {"status": "PASS", "message": "", "test_name": "test_special_content_handling", "rerun": "0"}, "11": {"status": "PASS", "message": "", "test_name": "test_content_structure_preservation", "rerun": "0"}}, "status": {"total_pass": 10, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 2, "total_error": 0}}, "9": {"suite_name": "tests/test_quality.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_quality_checker_initialization", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_content_length_check", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_heading_structure_check", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_link_validation", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_metadata_check", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_code_block_validation", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_quality_metrics_calculation", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_full_quality_check", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_quality_checker_cleanup", "rerun": "0"}}, "status": {"total_pass": 9, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 0, "total_error": 0}}, "10": {"suite_name": "tests/test_url_handling.py", "tests": {"0": {"status": "PASS", "message": "", "test_name": "test_urlunparse_behavior", "rerun": "0"}, "1": {"status": "PASS", "message": "", "test_name": "test_url_info_creation_basic", "rerun": "0"}, "2": {"status": "PASS", "message": "", "test_name": "test_url_info_path_normalization", "rerun": "0"}, "3": {"status": "PASS", "message": "", "test_name": "test_url_info_scheme_handling", "rerun": "0"}, "4": {"status": "PASS", "message": "", "test_name": "test_url_info_query_handling", "rerun": "0"}, "5": {"status": "PASS", "message": "", "test_name": "test_url_info_fragment_handling", "rerun": "0"}, "6": {"status": "PASS", "message": "", "test_name": "test_url_info_invalid_urls", "rerun": "0"}, "7": {"status": "PASS", "message": "", "test_name": "test_url_info_immutability", "rerun": "0"}, "8": {"status": "PASS", "message": "", "test_name": "test_url_info_equality", "rerun": "0"}, "9": {"status": "PASS", "message": "", "test_name": "test_url_info_type_safety", "rerun": "0"}, "10": {"status": "FAIL", "message": "       AssertionError: assert 'http://\u00fcnicode.com/' == 'http://xn--nicode-2ya.com/'\n         \n         - http://xn--nicode-2ya.com/\n         ?        ^^^^      ----\n         + http://\u00fcnicode.com/\n         ?        ^\n", "test_name": "test_url_info_edge_cases", "rerun": "0"}, "11": {"status": "FAIL", "message": "       assert True == False\n        +  where True = URLInfo(original=\"http://example.com/<script>alert('xss')</script>\", normalized=\"http://example.com/<script>alert('xss')</script>\", scheme='http', netloc='example.com', path=\"/<script>alert('xss')</script>\", is_valid=True).is_valid\n", "test_name": "test_url_info_security", "rerun": "0"}, "12": {"status": "FAIL", "message": "       TypeError: URLInfo.from_string() got an unexpected keyword argument 'base_url'\n", "test_name": "test_url_info_relative_paths", "rerun": "0"}, "13": {"status": "PASS", "message": "", "test_name": "test_url_info_query_parameters", "rerun": "0"}, "14": {"status": "PASS", "message": "", "test_name": "test_url_info_performance", "rerun": "0"}}, "status": {"total_pass": 12, "total_skip": 0, "total_xpass": 0, "total_xfail": 0, "total_rerun": 0, "total_fail": 3, "total_error": 0}}}}, "date": "November 27, 2024", "start_time": 1732704445.109312, "total_suite": 11, "status": "FAIL", "status_list": {"pass": "52", "fail": "54", "skip": "0", "error": "10", "xpass": "0", "xfail": "0", "rerun": "0"}, "total_tests": "116"}